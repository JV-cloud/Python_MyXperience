{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yns7z1dooSiw"
   },
   "source": [
    "# Exercício\n",
    "\n",
    "---\n",
    "- Treine um modelo de classificação DecisionTreeClassifier do pacote scikit-learn para classificar os produtos em suas categorias.\n",
    "- Experimente a lib SpaCy para remover as stop words e reduzir as palavras a seu lema. Veja como essas alterações impactam o desempenho do classificador.\n",
    "- Bônus!!! Use outro modelo de classificação do scikit-learn e compare seus resultados. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uhkRPtt4mxf9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://dados-ml-pln.s3-sa-east-1.amazonaws.com/produtos.csv\", delimiter=\";\", encoding='utf-8'\n",
    "  ).sample(frac=0.5, random_state=42)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df[\"texto\"] = df['nome'] + \" \" + df['descricao']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vkBLb7-uVJvt"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "df = pd.read_csv(\n",
    "    \"https://dados-ml-pln.s3-sa-east-1.amazonaws.com/produtos.csv\", delimiter=\";\", encoding='utf-8'\n",
    "  ).sample(1000)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "STMWVw3dsBOl",
    "outputId": "e3b256a2-f873-42bd-e24b-096e2b3758ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "livro        411\n",
       "maquiagem    387\n",
       "brinquedo    328\n",
       "game         298\n",
       "Name: categoria, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.categoria.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "RMG-cnHho8pi",
    "outputId": "4915f92b-b9f4-45ab-e3e6-4125e8a8a66b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "(1424, 23418)\n",
      "0.9543859649122807\n"
     ]
    }
   ],
   "source": [
    "# Exemplo 1: Vetorização por contagem de termos simples com unigrama, sem stopwords do NLTK e modelo de classificação DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk\n",
    "\n",
    "# stopwords NLTK\n",
    "nltk.download('stopwords')\n",
    "stops = nltk.corpus.stopwords.words('portuguese')\n",
    "\n",
    "# vetorização por contagem de termos\n",
    "#vect = CountVectorizer(ngram_range=(1,1)) # exemplo 1.1: vetorização unigrama com stopwords\n",
    "vect = CountVectorizer(ngram_range=(1,1), stop_words=stops) # exemplo 1.2: vetorização unigrama sem stopwords\n",
    "vect.fit(df.texto)\n",
    "text_vect = vect.transform(df.texto)\n",
    "\n",
    "# divisão da amostra entre treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "      text_vect, \n",
    "      df[\"categoria\"], \n",
    "      test_size = 0.2, \n",
    "      random_state = 42\n",
    "  )\n",
    "\n",
    "# treinamento do modelo ávore de decisão\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# escoragem da classificação na amostra de teste\n",
    "y_prediction = tree.predict(X_test)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "accuracy = accuracy_score(y_prediction, y_test)\n",
    "\n",
    "print(text_vect.shape)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iiFf6cRWXRkC"
   },
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download pt\n",
    "#!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NBkhv7TJpPRU"
   },
   "outputs": [],
   "source": [
    "# função de lematização completa do documento\n",
    "def lemmatizer_text(text):\n",
    "  sent = []\n",
    "  doc = nlp(text)\n",
    "  for word in doc:\n",
    "      sent.append(word.lemma_)\n",
    "  return \" \".join(sent)\n",
    "\n",
    "# função de lematização para os verbos do documento\n",
    "def lemmatizer_verbs(text):\n",
    "  sent = []\n",
    "  doc = nlp(text)\n",
    "  for word in doc:\n",
    "      if word.pos_ == \"VERB\":\n",
    "          sent.append(word.lemma_)\n",
    "      else:\n",
    "          sent.append(word.text)\n",
    "  return \" \".join(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "YV5GVlPFq-rG",
    "outputId": "efdc7bb0-fa45-4a28-dc75-7e907aac9c8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correr 1 , 2 , 3\n",
      "correr 1 , 2 , 3\n"
     ]
    }
   ],
   "source": [
    "# teste das funções de lematização\n",
    "#!pip install spacy\n",
    "#!python -m spacy download pt\n",
    "import spacy\n",
    "nlp = spacy.load('pt')\n",
    "\n",
    "# validação das funções\n",
    "print(lemmatizer_text('correndo 1, 2, 3'))\n",
    "print(lemmatizer_verbs('correndo 1, 2, 3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gLz7qvbj2WVm"
   },
   "outputs": [],
   "source": [
    "# aplica a lematização no dataframe criando novas colunas\n",
    "df['text_lemma'] = df.texto.apply(lemmatizer_text)\n",
    "df['text_lemma_verbs'] = df.texto.apply(lemmatizer_verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "n8jQNEBhUeOW",
    "outputId": "44ecdd1f-7288-4480-a0d2-75748aaa80d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1424 entries, 33 to 2615\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   nome              1424 non-null   object\n",
      " 1   descricao         1424 non-null   object\n",
      " 2   categoria         1424 non-null   object\n",
      " 3   texto             1424 non-null   object\n",
      " 4   text_lemma        1424 non-null   object\n",
      " 5   text_lemma_verbs  1424 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 117.9+ KB\n",
      "None\n",
      "\n",
      "shape:  (1424, 6)\n",
      "                                                   nome  ...                                   text_lemma_verbs\n",
      "33                                      Extraordinário   ...    Extraordinário   Produto Novo“Extraordinário...\n",
      "3316   Fifa 2018 Narração Português Completo Midia D...  ...    Fifa 2018 Narração Português Completo Midia ...\n",
      "\n",
      "[2 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# análise dos dados e nova estrutura do dataframe\n",
    "print(df.info())\n",
    "print('\\nshape: ', df.shape)\n",
    "print(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "3rabyoXjzQCn",
    "outputId": "8789c8e6-c6f6-48ad-d72f-78fb431cb675"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " O Hobbit - 7ª Ed. 2013  Produto NovoBilbo Bolseiro é um hobbit que leva uma vida confortável e sem ambições. Mas seu contentamento é perturbado quando Gandalf, o mago, e uma companhia de anões batem à sua porta e levam-no para uma expedição. Eles têm um plano para roubar o tesouro guardado por Smaug, o Magnífico, um grande e perigoso dragão. Bilbo reluta muito em participar da aventura, mas acaba surpreendendo até a si mesmo com sua esperteza e sua habilidade como ladrão!CaracterísticasAutor: Tolkien, J. R. R.Peso: 0.44I.S.B.N.: 9788578277109Altura: 20.000000Largura: 13.000000Profundidade: 1.000000Número de Páginas: 328Idioma: PortuguêsAcabamento: BrochuraNúmero da edição: 7Ano da edição: 2013\n",
      "  O Hobbit - 7ª Ed . 2013   Produto NovoBilbo Bolseiro ser um hobbit que levar umar vidar confortável e sem ambição . Mas seu contentamento ser perturbar quando Gandalf , o mago , e umar companhia de anão bater à suar portar e levam-no parir umar expedição . Eles ter um planar parir roubar o tesourar guardar por Smaug , o Magnífico , um grande e perigoso dragão . Bilbo relutar muito em participar da aventurar , mas acabar surpreender até o si mesmo com suar esperteza e suar habilidade comer ladrão!CaracterísticasAutor : Tolkien , J. R. R.Peso : 0.44I.S.B.N. : 9788578277109Altura : 20.000000Largura : 13.000000Profundidade : 1.000000Número de Páginas : 328Idioma : PortuguêsAcabamento : BrochuraNúmero da edição : 7Ano da edição : 2013\n",
      "  O Hobbit - 7ª Ed . 2013   Produto NovoBilbo Bolseiro ser um hobbit que levar uma vida confortável e sem ambições . Mas seu contentamento é perturbar quando Gandalf , o mago , e uma companhia de anões bater à sua porta e levam-no para uma expedição . Eles ter um plano para roubar o tesouro guardar por Smaug , o Magnífico , um grande e perigoso dragão . Bilbo relutar muito em participar da aventura , mas acaba surpreender até a si mesmo com sua esperteza e sua habilidade como ladrão!CaracterísticasAutor : Tolkien , J. R. R.Peso : 0.44I.S.B.N. : 9788578277109Altura : 20.000000Largura : 13.000000Profundidade : 1.000000Número de Páginas : 328Idioma : PortuguêsAcabamento : BrochuraNúmero da edição : 7Ano da edição : 2013\n"
     ]
    }
   ],
   "source": [
    "# análise para comparação dos textos\n",
    "print(df['texto'][0])\n",
    "print(df['text_lemma'][0])\n",
    "print(df['text_lemma_verbs'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "YcUoUN-UsiTf",
    "outputId": "5ce81bea-e0db-4184-bec1-4dee0c85bfe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1424, 100498)\n",
      "0.9508771929824561\n"
     ]
    }
   ],
   "source": [
    "# Exemplo 2: vetorização por contagem de termos simples com a combinação de unigrama e bigrama no documento lematizado, sem stopwords do SpaCy e modelo de classificação DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import spacy\n",
    "\n",
    "# stopwords SpaCy\n",
    "nlp = spacy.load('pt')\n",
    "stops = nlp.Defaults.stop_words\n",
    "\n",
    "# vetorização por contagem de termos no documento lematizado\n",
    "#vect = CountVectorizer(ngram_range=(1,1), stop_words=stops) # exemplo 2.1: vetorização e combinação de unigrama sem stopwords\n",
    "vect = CountVectorizer(ngram_range=(1,2), stop_words=stops) # exemplo 2.2: vetorização e combinação de unigrama e bigrama sem stopwords\n",
    "vect.fit(df.text_lemma)\n",
    "text_vect = vect.transform(df.text_lemma)\n",
    "\n",
    "# divisão da amostra entre treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "      text_vect, \n",
    "      df[\"categoria\"], \n",
    "      test_size = 0.2, \n",
    "      random_state = 42\n",
    "  )\n",
    "\n",
    "# treinamento do modelo ávore de decisão\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# escoragem da classificação na amostra de teste\n",
    "y_prediction = tree.predict(X_test)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "accuracy = accuracy_score(y_prediction, y_test)\n",
    "\n",
    "print(text_vect.shape)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "vsjOD_P5hAIc",
    "outputId": "15dda9d6-b8e4-4e3d-8411-b8afa6a8b134"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1424, 100384)\n",
      "0.9614035087719298\n"
     ]
    }
   ],
   "source": [
    "# Exemplo 3: Vetorização por contagem de termos simples com a combinação de unigrama e bigrama no documento com verbos lematizado, sem stopwords do SpaCy e modelo de classificação DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import spacy\n",
    "\n",
    "# stopwords SpaCy\n",
    "nlp = spacy.load('pt')\n",
    "stops = nlp.Defaults.stop_words\n",
    "\n",
    "# vetorização por contagem de termos no documento com os verbos lematizado\n",
    "#vect = CountVectorizer(ngram_range=(1,1), stop_words=stops) # exemplo 3.1: vetorização e combinação de unigrama sem stopwords\n",
    "vect = CountVectorizer(ngram_range=(1,2), stop_words=stops) # exemplo 3.2: vetorização e combinação de unigrama e bigrama sem stopwords\n",
    "vect.fit(df.text_lemma_verbs)\n",
    "text_vect = vect.transform(df.text_lemma_verbs)\n",
    "\n",
    "# divisão da amostra entre treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "      text_vect, \n",
    "      df[\"categoria\"], \n",
    "      test_size = 0.2, \n",
    "      random_state = 42\n",
    "  )\n",
    "\n",
    "# treinamento do modelo ávore de decisão\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# escoragem da classificação na amostra de teste\n",
    "y_prediction = tree.predict(X_test)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "accuracy = accuracy_score(y_prediction, y_test)\n",
    "\n",
    "print(text_vect.shape)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "CG51OO8KlduJ",
    "outputId": "2adb05d7-e7fa-43e9-ff06-88486abc55e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "(1424, 100086)\n",
      "0.9578947368421052\n"
     ]
    }
   ],
   "source": [
    "# Exemplo 4: Vetorização por contagem de termos simples com a combinação de unigrama e bigrama no documento com verbos lematizado, sem stopwords do SpaCy e NLTK combinadas e modelo de classificação DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import spacy\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nlp = spacy.load('pt')\n",
    "\n",
    "# stopwords do SpaCy e NLTK combinadas\n",
    "stops = list(set(nlp.Defaults.stop_words).union(set(nltk.corpus.stopwords.words('portuguese'))))\n",
    "#len(stops)\n",
    "\n",
    "# vetorização por contagem de termos no documento com os verbos lematizado\n",
    "vect = CountVectorizer(ngram_range=(1,2), stop_words=stops) # exemplo 4.1: vetorização e combinação de unigrama e bigrama sem stopwords NLTK e Spacy\n",
    "vect.fit(df.text_lemma_verbs)\n",
    "text_vect = vect.transform(df.text_lemma_verbs)\n",
    "\n",
    "# divisão da amostra entre treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "      text_vect, \n",
    "      df[\"categoria\"], \n",
    "      test_size = 0.2, \n",
    "      random_state = 42\n",
    "  )\n",
    "\n",
    "# treinamento do modelo ávore de decisão\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# escoragem da classificação na amostra de teste\n",
    "y_prediction = tree.predict(X_test)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "accuracy = accuracy_score(y_prediction, y_test)\n",
    "\n",
    "print(text_vect.shape)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "qGTuFeHdMLCX",
    "outputId": "10154b47-3a0e-4752-aa4e-da8ac7376ad4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "(1424, 19961)\n",
      "0.9614035087719298\n"
     ]
    }
   ],
   "source": [
    "# Exemplo 5: Vetorização por contagem de termos TF-IDF com a combinação de unigrama com documentos lematizado, sem stopwords do SpaCy e NLTK combinadas e modelo de classificação DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import spacy\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nlp = spacy.load('pt')\n",
    "\n",
    "# stopwords do SpaCy e NLTK combinadas\n",
    "stops_spacy = nlp.Defaults.stop_words\n",
    "stops_nltk = nltk.corpus.stopwords.words('portuguese')\n",
    "stops = list(set(stops_spacy).union(set(stops_nltk)))\n",
    "\n",
    "# vetorização por contagem de termos no documento lematizado\n",
    "vetorTfidf = TfidfVectorizer(ngram_range=(1,1), use_idf=True, stop_words=stops, norm='l2') # exemplo 4.1: vetorização tf-idf e combinação de unigrama sem stopwords NLTK e Spacy\n",
    "#vetorTfidf = TfidfVectorizer(ngram_range=(1,2), use_idf=True, stop_words=stops_spacy, norm='l2') # exemplo 4.2: vetorização tf-idf e combinação de unigrama e bigrama sem stopwords NLTK e Spacy\n",
    "#vetorTfidf = TfidfVectorizer(ngram_range=(1,2), use_idf=False, stop_words=stops_spacy, norm='l1') # exemplo 4.3: vetorização tf e combinação de unigrama e bigrama sem stopwords NLTK e Spacy\n",
    "vetorTfidf.fit(df.text_lemma)\n",
    "text_vect = vetorTfidf.transform(df.text_lemma)\n",
    "\n",
    "# divisão da amostra entre treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "      text_vect, \n",
    "      df[\"categoria\"], \n",
    "      test_size = 0.2, \n",
    "      random_state = 42\n",
    "  )\n",
    "\n",
    "# treinamento do modelo ávore de decisão\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# escoragem da classificação na amostra de teste\n",
    "y_prediction = tree.predict(X_test)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "accuracy = accuracy_score(y_prediction, y_test)\n",
    "\n",
    "print(text_vect.shape)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "bC8VbMbL2Lou",
    "outputId": "d4c35cbf-918b-49f9-cbfe-f94d443756c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "(1424, 21436)\n",
      "0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "# Exemplo 6: Vetorização por contagem de termos TF-IDF com a combinação de unigrama com documentos com verbos lematizado, sem stopwords do SpaCy e NLTK combinadas e modelo de classificação Regressão Logistica\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import spacy\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nlp = spacy.load('pt')\n",
    "\n",
    "# stopwords do SpaCy e NLTK combinadas\n",
    "stops_spacy = nlp.Defaults.stop_words\n",
    "stops_nltk = nltk.corpus.stopwords.words('portuguese')\n",
    "stops = list(set(stops_spacy).union(set(stops_nltk)))\n",
    "\n",
    "# vetorização por contagem de termos no documento lematizado\n",
    "vetorTfidf = TfidfVectorizer(ngram_range=(1,1), use_idf=True, stop_words=stops, norm='l2')\n",
    "vetorTfidf.fit(df.text_lemma_verbs)\n",
    "text_vect = vetorTfidf.transform(df.text_lemma_verbs)\n",
    "\n",
    "# treinamento do modelo ávore de decisão\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# escoragem da classificação na amostra de teste\n",
    "y_prediction = model.predict(X_test)\n",
    "\n",
    "# mensuração do resultado pela acurácia\n",
    "accuracy = accuracy_score(y_prediction, y_test)\n",
    "\n",
    "print(text_vect.shape)\n",
    "print(accuracy)\n",
    "\n",
    "# Nosso melhor modelo até aqui!!! :)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Aula 4 IA PLN - Exercicio.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
