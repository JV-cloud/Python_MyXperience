{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aula 3 IA PLN - Demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdelQOET5rDj",
        "colab_type": "text"
      },
      "source": [
        "#**Processamento de Linguagem Natural**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0wg8wf1GSeD",
        "colab_type": "text"
      },
      "source": [
        "## Stemmer (Stemização)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfwMue5RGR8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "ps = PorterStemmer()\n",
        "exemplos = [\"connection\",\"connections\",\"connective\",\"connecting\",\"connected\"]\n",
        "print(exemplos)\n",
        "\n",
        "for word in exemplos:\n",
        "  print(ps.stem(word))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiXeQyMcAx4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Outro exemplo\n",
        "ps = PorterStemmer()\n",
        "exemplos = [\"go\",\"going\",\"goes\",\"gone\",\"went\"]\n",
        "print(exemplos)\n",
        "\n",
        "for word in exemplos:\n",
        "  print(ps.stem(word))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIvuXLMeqUd9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Stemização\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem.rslp import RSLPStemmer\n",
        "import nltk \n",
        "nltk.download('rslp')\n",
        "\n",
        "doc = [\"pedra\",\"pedreira\"]\n",
        "print(doc)\n",
        "\n",
        "ps = PorterStemmer()\n",
        "rslp = RSLPStemmer()\n",
        "\n",
        "for word in doc:\n",
        "    print(ps.stem(word), ' - ', rslp.stem(word))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVDjrt-eT4MV",
        "colab_type": "text"
      },
      "source": [
        "## Aplicar Stemmer em uma frase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nGuydG4xrJFd",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'text': [\n",
        "      'Sobre MBA? Eu gostei muito do MBA da FIAP',\n",
        "      'O MBA da FIAP pode melhorar, não gostei muito'\n",
        "    ],\n",
        "    'class': [\n",
        "        'positivo',\n",
        "        'negativo'\n",
        "    ]})\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6_SwqMGibny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "df['tokens'] = df.text.apply(word_tokenize)\n",
        "df['tokens']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBJ-oLU9T3jT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem.rslp import RSLPStemmer\n",
        "import nltk\n",
        "nltk.download('rslp')\n",
        "\n",
        "tokens = df.tokens[0]\n",
        "tokens = tokens + df.tokens[1]\n",
        "\n",
        "ps = PorterStemmer()\n",
        "rslp = RSLPStemmer()\n",
        "\n",
        "for tok in tokens:\n",
        "  print('Original: %s \\t\\t  PorterStemmer: %s \\t\\t RSLPStemmer: %s' % (tok, ps.stem(tok), rslp.stem(tok)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37nqnDh-qVnA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# O Porter foi criado para o inglês e o RSLP para o português"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QGwgdjvSW7L",
        "colab_type": "text"
      },
      "source": [
        "NLTK = Natural Language Tool Kit\n",
        "\n",
        "RSLP = Removedor de Sulfixos da Língua Portuguesa\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhTMo3h0oFA7",
        "colab_type": "text"
      },
      "source": [
        "## Quantos unigramas existem após aplicar Stemmer?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlUI2NgDhufq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "','.join(['Anderson', 'Dourado'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_3LR9sO0hRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem.rslp import RSLPStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "rslp = RSLPStemmer()\n",
        "\n",
        "def stem_pandas(line):\n",
        "  return ' '.join([rslp.stem(token) for token in line])\n",
        "\n",
        "df['stemmer'] = df.tokens.apply(stem_pandas)\n",
        "\n",
        "df.stemmer.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFiA2cAORmpc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
        "#vect = CountVectorizer(ngram_range=(1,1), stop_words=stopwords)\n",
        "vect = CountVectorizer(ngram_range=(1,1))\n",
        "vect.fit(df.stemmer)\n",
        "\n",
        "text_vect = vect.transform(df.stemmer)\n",
        "\n",
        "print('UNIGRAMAS sem STOPWORDS', text_vect.shape[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofA1n_IMkb_t",
        "colab_type": "text"
      },
      "source": [
        "Unigramas sem aplicar o steamm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAfnfeu8kbSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#stopwords = nltk.corpus.stopwords.words('portuguese')\n",
        "#vect = CountVectorizer(ngram_range=(1,1), stop_words=stopwords)\n",
        "vect = CountVectorizer(ngram_range=(1,1))\n",
        "vect.fit(df.text)\n",
        "\n",
        "text_vect = vect.transform(df.text)\n",
        "\n",
        "print('UNIGRAMAS sem STOPWORDS', text_vect.shape[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCHgWx60kbPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Não diferença pois o texto não tem muitas variações de palavras que possam ser reduzidas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr8ZxTp-pVPC",
        "colab_type": "text"
      },
      "source": [
        "Outra função de stematização do NLTK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngaGMoCjpL4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "print(\" \".join(SnowballStemmer.languages)) # See which languages are supported"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1inKMGdpLu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stemmer = SnowballStemmer(\"portuguese\") # Escolha a linguagem\n",
        "\n",
        "palavras = ['pedra','pedreira','criar']\n",
        "\n",
        "for p in palavras:\n",
        "  print(stemmer.stem(p)) # Stem a palavra"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cDR2TTl-EnXs"
      },
      "source": [
        "## Lemmatizer (Lematização)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBLzygcrElkJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "exemplos = [\"connection\",\"connections\",\"connective\",\"connecting\",\"connected\"]\n",
        "wnl = WordNetLemmatizer()\n",
        "\n",
        "for word in exemplos:\n",
        "    print(wnl.lemmatize(word,\"v\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wTZpIniE39a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "exemplos = [\"go\",\"going\",\"goes\",\"gone\",\"went\"]\n",
        "wnl = WordNetLemmatizer()\n",
        "\n",
        "for word in exemplos:\n",
        "  print(wnl.lemmatize(word,\"v\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ndw8rAQbofuL",
        "colab_type": "text"
      },
      "source": [
        "Vamos ver lematização em palavras do português mais para frente, pois o NLTK não possui lematização em português.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqCkOL0C5-FC",
        "colab_type": "text"
      },
      "source": [
        "## Contagem de Termos - UNIGRAMA\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4CKjpwJ2DD2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({\n",
        "    'text': [\n",
        "      'Sobre MBA ? Eu gostei muito do MBA da FIAP',\n",
        "      'O MBA da FIAP pode melhorar, não gostei muito'\n",
        "    ],\n",
        "    'class': [\n",
        "        'positivo',\n",
        "        'negativo'\n",
        "    ]})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6kSv69h2jKs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vect = CountVectorizer(ngram_range=(1,1))\n",
        "#vect = CountVectorizer(ngram_range=(2,2))\n",
        "vect.fit(df.text)\n",
        "count_vect = vect.transform(df.text)\n",
        "\n",
        "print(pd.DataFrame(count_vect.A, columns=vect.get_feature_names()).T.to_string())\n",
        "#print(pd.DataFrame(count_vect.A, columns=vect.get_feature_names()).to_string())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUTv5MDZE0jr",
        "colab_type": "text"
      },
      "source": [
        "## TF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHgB0DuUCn65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# ao usar o TfidfVectorizer() o default ngram_range=unigrama, use_idf=True, norm='l2', lowercase=True, max_df e min_df=1, smooth_idf=True, sublinear_tf=False\n",
        "vect = TfidfVectorizer(ngram_range=(1,1), use_idf=False, norm='l1')\n",
        "vect.fit(df.text)\n",
        "tf_vect = vect.transform(df.text)\n",
        "\n",
        "print(pd.DataFrame(tf_vect.A, columns=vect.get_feature_names()).T.to_string())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCpY8Zww3o47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#vect.get_stop_words()\n",
        "#vect.get_params(deep=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxG2g5mInypI",
        "colab_type": "text"
      },
      "source": [
        "## TF-IDF\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcJsUXuHFTnM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# ao usar o TfidfVectorizer() o default ngram_range=unigrama, use_idf=True, norm='l2', lowercase=True, max_df e min_df=1, smooth_idf=True, sublinear_tf=False\n",
        "vect = TfidfVectorizer() \n",
        "vect.fit(df.text)\n",
        "tfidf_vect = vect.transform(df.text)\n",
        "\n",
        "print(pd.DataFrame(tfidf_vect.A, columns=vect.get_feature_names()).T.to_string())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zb4iAoq2ZoqW",
        "colab_type": "text"
      },
      "source": [
        "Existe uma diferenca no cálculo original do TF-IDF apresentados pelos livros em relação ao padrão urilizado pelo Scikit Learn. A ideia dessa diferença é evitar divisões por zero.\n",
        "\n",
        "Formúla original:\n",
        "\n",
        "    TF-IDFw1 = TFw1 * IDFw1\n",
        "    IDFw1 = loge(D/Dw1)\n",
        "    D = total de documentos | Dw1 = Quantidade de documentos em que o termo aparece\n",
        "\n",
        "----\n",
        "Formúla do sklearn:\n",
        "Muda o cálculo do IDFw1\n",
        "\n",
        "    IDFw! = loge(1+D/1+Dw1)+1\n",
        "\n",
        "Com o paâmetro smooth_idf=False\n",
        "\n",
        "    IDFw! = loge(D/Dw1)+1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYvr0cay4JbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# ao usar o TfidfVectorizer() o default ngram_range=unigrama, use_idf=True, norm='l2', lowercase=True, max_df e min_df=1, smooth_idf=True, sublinear_tf=False\n",
        "vect = TfidfVectorizer(smooth_idf=False)\n",
        "#vect = TfidfVectorizer(smooth_idf=False, max_df=1, min_df=1)\n",
        "vect.fit(df.text)\n",
        "tfidf_vect = vect.transform(df.text)\n",
        "\n",
        "print(pd.DataFrame(tfidf_vect.A, columns=vect.get_feature_names()).T.to_string())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEps9zD-u4v_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "tfidf_vect.data\n",
        "tfidf_vect.A\n",
        "vect.get_feature_names()\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0WHVK8HYG5r",
        "colab_type": "text"
      },
      "source": [
        "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer\n",
        "\n",
        "\n",
        "https://scikit-learn.org/stable/modules/feature_extraction.html\n",
        "\n",
        "O cáculo do TF-IDF das classes TfidfTransformer e TfidfVectorizer do scikit-learn diferem ligeiramente da notação padrão de livros didáticos que define o IDF.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owZf_DaUomwT",
        "colab_type": "text"
      },
      "source": [
        "## Modelo com n-grama"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbiAa2z89dy3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4lp9qev2BwO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['class']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3p0_VlNmzAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# treinando um modelo de árevore de decisão\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "tree = DecisionTreeClassifier()\n",
        "tree.fit(tfidf_vect, df['class'])\n",
        "\n",
        "print('D Tree: ', tree.score(tfidf_vect, df['class'])) # retorna a acurracy - precisão do modelo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MD07UNay3hA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tree.score(tfidf_vect, df['class'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuGLwdhUpuIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vetor = vect.transform(['a vovo juju adora abacate'])\n",
        "\n",
        "print('D Tree: ', tree.predict(vetor))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2-ZCeUkYiJ1",
        "colab_type": "text"
      },
      "source": [
        "Salvando o modelo treinado e o vetor de tranformação."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2R6-1s4wqEiq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "pickle.dump(tree, open('minhaarvore.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DE_UGqF1tI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -la"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CsH-JyC3rGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "blaaaaa = pickle.load(open('minhaarvore.pkl', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLsZNb1R4EIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('D Tree: ', blaaaaa.predict(texto)) # texto = vetor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vdnmYmE4PYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "# mostrar a estrutura de pastas do google drive montado"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKUrqfZ_ABaC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "pickle.dump(tree, open('/content/gdrive/My Drive/FIAP/NLP/minhaarvore.pkl', 'wb'))\n",
        "\n",
        "pickle.dump(vect, open('/content/gdrive/My Drive/FIAP/NLP/vetorizador.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}