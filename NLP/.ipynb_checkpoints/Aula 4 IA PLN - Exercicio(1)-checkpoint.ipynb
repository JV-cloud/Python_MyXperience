{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aula 4 IA PLN - Exercicio.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yns7z1dooSiw",
        "colab_type": "text"
      },
      "source": [
        "# Exercício\n",
        "\n",
        "---\n",
        "- Treine um modelo de classificação DecisionTreeClassifier do pacote scikit-learn para classificar os produtos em suas categorias.\n",
        "- Experimente a lib SpaCy para remover as stop words e reduzir as palavras a seu lema. Veja como essas alterações impactam o desempenho do classificador.\n",
        "- Bônus!!! Use outro modelo de classificação do scikit-learn e compare seus resultados. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhkRPtt4mxf9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\n",
        "    \"https://dados-ml-pln.s3-sa-east-1.amazonaws.com/produtos.csv\", delimiter=\";\", encoding='utf-8'\n",
        "  ).sample(frac=0.5, random_state=42)\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "df[\"texto\"] = df['nome'] + \" \" + df['descricao']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkBLb7-uVJvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "df = pd.read_csv(\n",
        "    \"https://dados-ml-pln.s3-sa-east-1.amazonaws.com/produtos.csv\", delimiter=\";\", encoding='utf-8'\n",
        "  ).sample(1000)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STMWVw3dsBOl",
        "colab_type": "code",
        "outputId": "e3b256a2-f873-42bd-e24b-096e2b3758ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "df.categoria.value_counts()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "livro        411\n",
              "maquiagem    387\n",
              "brinquedo    328\n",
              "game         298\n",
              "Name: categoria, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMG-cnHho8pi",
        "colab_type": "code",
        "outputId": "4915f92b-b9f4-45ab-e3e6-4125e8a8a66b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Exemplo 1: Vetorização por contagem de termos simples com unigrama, sem stopwords do NLTK e modelo de classificação DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import nltk\n",
        "\n",
        "# stopwords NLTK\n",
        "nltk.download('stopwords')\n",
        "stops = nltk.corpus.stopwords.words('portuguese')\n",
        "\n",
        "# vetorização por contagem de termos\n",
        "#vect = CountVectorizer(ngram_range=(1,1)) # exemplo 1.1: vetorização unigrama com stopwords\n",
        "vect = CountVectorizer(ngram_range=(1,1), stop_words=stops) # exemplo 1.2: vetorização unigrama sem stopwords\n",
        "vect.fit(df.texto)\n",
        "text_vect = vect.transform(df.texto)\n",
        "\n",
        "# divisão da amostra entre treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "      text_vect, \n",
        "      df[\"categoria\"], \n",
        "      test_size = 0.2, \n",
        "      random_state = 42\n",
        "  )\n",
        "\n",
        "# treinamento do modelo ávore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "y_prediction = tree.predict(X_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "accuracy = accuracy_score(y_prediction, y_test)\n",
        "\n",
        "print(text_vect.shape)\n",
        "print(accuracy)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "(1424, 23418)\n",
            "0.9543859649122807\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiFf6cRWXRkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download pt\n",
        "#!python -m spacy download en"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBkhv7TJpPRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# função de lematização completa do documento\n",
        "def lemmatizer_text(text):\n",
        "  sent = []\n",
        "  doc = nlp(text)\n",
        "  for word in doc:\n",
        "      sent.append(word.lemma_)\n",
        "  return \" \".join(sent)\n",
        "\n",
        "# função de lematização para os verbos do documento\n",
        "def lemmatizer_verbs(text):\n",
        "  sent = []\n",
        "  doc = nlp(text)\n",
        "  for word in doc:\n",
        "      if word.pos_ == \"VERB\":\n",
        "          sent.append(word.lemma_)\n",
        "      else:\n",
        "          sent.append(word.text)\n",
        "  return \" \".join(sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YV5GVlPFq-rG",
        "colab_type": "code",
        "outputId": "efdc7bb0-fa45-4a28-dc75-7e907aac9c8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# teste das funções de lematização\n",
        "#!pip install spacy\n",
        "#!python -m spacy download pt\n",
        "import spacy\n",
        "nlp = spacy.load('pt')\n",
        "\n",
        "# validação das funções\n",
        "print(lemmatizer_text('correndo 1, 2, 3'))\n",
        "print(lemmatizer_verbs('correndo 1, 2, 3'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "correr 1 , 2 , 3\n",
            "correr 1 , 2 , 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLz7qvbj2WVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# aplica a lematização no dataframe criando novas colunas\n",
        "df['text_lemma'] = df.texto.apply(lemmatizer_text)\n",
        "df['text_lemma_verbs'] = df.texto.apply(lemmatizer_verbs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8jQNEBhUeOW",
        "colab_type": "code",
        "outputId": "44ecdd1f-7288-4480-a0d2-75748aaa80d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# análise dos dados e nova estrutura do dataframe\n",
        "print(df.info())\n",
        "print('\\nshape: ', df.shape)\n",
        "print(df.head(2))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1424 entries, 33 to 2615\n",
            "Data columns (total 6 columns):\n",
            " #   Column            Non-Null Count  Dtype \n",
            "---  ------            --------------  ----- \n",
            " 0   nome              1424 non-null   object\n",
            " 1   descricao         1424 non-null   object\n",
            " 2   categoria         1424 non-null   object\n",
            " 3   texto             1424 non-null   object\n",
            " 4   text_lemma        1424 non-null   object\n",
            " 5   text_lemma_verbs  1424 non-null   object\n",
            "dtypes: object(6)\n",
            "memory usage: 117.9+ KB\n",
            "None\n",
            "\n",
            "shape:  (1424, 6)\n",
            "                                                   nome  ...                                   text_lemma_verbs\n",
            "33                                      Extraordinário   ...    Extraordinário   Produto Novo“Extraordinário...\n",
            "3316   Fifa 2018 Narração Português Completo Midia D...  ...    Fifa 2018 Narração Português Completo Midia ...\n",
            "\n",
            "[2 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rabyoXjzQCn",
        "colab_type": "code",
        "outputId": "8789c8e6-c6f6-48ad-d72f-78fb431cb675",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# análise para comparação dos textos\n",
        "print(df['texto'][0])\n",
        "print(df['text_lemma'][0])\n",
        "print(df['text_lemma_verbs'][0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " O Hobbit - 7ª Ed. 2013  Produto NovoBilbo Bolseiro é um hobbit que leva uma vida confortável e sem ambições. Mas seu contentamento é perturbado quando Gandalf, o mago, e uma companhia de anões batem à sua porta e levam-no para uma expedição. Eles têm um plano para roubar o tesouro guardado por Smaug, o Magnífico, um grande e perigoso dragão. Bilbo reluta muito em participar da aventura, mas acaba surpreendendo até a si mesmo com sua esperteza e sua habilidade como ladrão!CaracterísticasAutor: Tolkien, J. R. R.Peso: 0.44I.S.B.N.: 9788578277109Altura: 20.000000Largura: 13.000000Profundidade: 1.000000Número de Páginas: 328Idioma: PortuguêsAcabamento: BrochuraNúmero da edição: 7Ano da edição: 2013\n",
            "  O Hobbit - 7ª Ed . 2013   Produto NovoBilbo Bolseiro ser um hobbit que levar umar vidar confortável e sem ambição . Mas seu contentamento ser perturbar quando Gandalf , o mago , e umar companhia de anão bater à suar portar e levam-no parir umar expedição . Eles ter um planar parir roubar o tesourar guardar por Smaug , o Magnífico , um grande e perigoso dragão . Bilbo relutar muito em participar da aventurar , mas acabar surpreender até o si mesmo com suar esperteza e suar habilidade comer ladrão!CaracterísticasAutor : Tolkien , J. R. R.Peso : 0.44I.S.B.N. : 9788578277109Altura : 20.000000Largura : 13.000000Profundidade : 1.000000Número de Páginas : 328Idioma : PortuguêsAcabamento : BrochuraNúmero da edição : 7Ano da edição : 2013\n",
            "  O Hobbit - 7ª Ed . 2013   Produto NovoBilbo Bolseiro ser um hobbit que levar uma vida confortável e sem ambições . Mas seu contentamento é perturbar quando Gandalf , o mago , e uma companhia de anões bater à sua porta e levam-no para uma expedição . Eles ter um plano para roubar o tesouro guardar por Smaug , o Magnífico , um grande e perigoso dragão . Bilbo relutar muito em participar da aventura , mas acaba surpreender até a si mesmo com sua esperteza e sua habilidade como ladrão!CaracterísticasAutor : Tolkien , J. R. R.Peso : 0.44I.S.B.N. : 9788578277109Altura : 20.000000Largura : 13.000000Profundidade : 1.000000Número de Páginas : 328Idioma : PortuguêsAcabamento : BrochuraNúmero da edição : 7Ano da edição : 2013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcUoUN-UsiTf",
        "colab_type": "code",
        "outputId": "5ce81bea-e0db-4184-bec1-4dee0c85bfe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Exemplo 2: vetorização por contagem de termos simples com a combinação de unigrama e bigrama no documento lematizado, sem stopwords do SpaCy e modelo de classificação DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import spacy\n",
        "\n",
        "# stopwords SpaCy\n",
        "nlp = spacy.load('pt')\n",
        "stops = nlp.Defaults.stop_words\n",
        "\n",
        "# vetorização por contagem de termos no documento lematizado\n",
        "#vect = CountVectorizer(ngram_range=(1,1), stop_words=stops) # exemplo 2.1: vetorização e combinação de unigrama sem stopwords\n",
        "vect = CountVectorizer(ngram_range=(1,2), stop_words=stops) # exemplo 2.2: vetorização e combinação de unigrama e bigrama sem stopwords\n",
        "vect.fit(df.text_lemma)\n",
        "text_vect = vect.transform(df.text_lemma)\n",
        "\n",
        "# divisão da amostra entre treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "      text_vect, \n",
        "      df[\"categoria\"], \n",
        "      test_size = 0.2, \n",
        "      random_state = 42\n",
        "  )\n",
        "\n",
        "# treinamento do modelo ávore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "y_prediction = tree.predict(X_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "accuracy = accuracy_score(y_prediction, y_test)\n",
        "\n",
        "print(text_vect.shape)\n",
        "print(accuracy)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1424, 100498)\n",
            "0.9508771929824561\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsjOD_P5hAIc",
        "colab_type": "code",
        "outputId": "15dda9d6-b8e4-4e3d-8411-b8afa6a8b134",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Exemplo 3: Vetorização por contagem de termos simples com a combinação de unigrama e bigrama no documento com verbos lematizado, sem stopwords do SpaCy e modelo de classificação DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import spacy\n",
        "\n",
        "# stopwords SpaCy\n",
        "nlp = spacy.load('pt')\n",
        "stops = nlp.Defaults.stop_words\n",
        "\n",
        "# vetorização por contagem de termos no documento com os verbos lematizado\n",
        "#vect = CountVectorizer(ngram_range=(1,1), stop_words=stops) # exemplo 3.1: vetorização e combinação de unigrama sem stopwords\n",
        "vect = CountVectorizer(ngram_range=(1,2), stop_words=stops) # exemplo 3.2: vetorização e combinação de unigrama e bigrama sem stopwords\n",
        "vect.fit(df.text_lemma_verbs)\n",
        "text_vect = vect.transform(df.text_lemma_verbs)\n",
        "\n",
        "# divisão da amostra entre treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "      text_vect, \n",
        "      df[\"categoria\"], \n",
        "      test_size = 0.2, \n",
        "      random_state = 42\n",
        "  )\n",
        "\n",
        "# treinamento do modelo ávore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "y_prediction = tree.predict(X_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "accuracy = accuracy_score(y_prediction, y_test)\n",
        "\n",
        "print(text_vect.shape)\n",
        "print(accuracy)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1424, 100384)\n",
            "0.9614035087719298\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG51OO8KlduJ",
        "colab_type": "code",
        "outputId": "2adb05d7-e7fa-43e9-ff06-88486abc55e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Exemplo 4: Vetorização por contagem de termos simples com a combinação de unigrama e bigrama no documento com verbos lematizado, sem stopwords do SpaCy e NLTK combinadas e modelo de classificação DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import spacy\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nlp = spacy.load('pt')\n",
        "\n",
        "# stopwords do SpaCy e NLTK combinadas\n",
        "stops = list(set(nlp.Defaults.stop_words).union(set(nltk.corpus.stopwords.words('portuguese'))))\n",
        "#len(stops)\n",
        "\n",
        "# vetorização por contagem de termos no documento com os verbos lematizado\n",
        "vect = CountVectorizer(ngram_range=(1,2), stop_words=stops) # exemplo 4.1: vetorização e combinação de unigrama e bigrama sem stopwords NLTK e Spacy\n",
        "vect.fit(df.text_lemma_verbs)\n",
        "text_vect = vect.transform(df.text_lemma_verbs)\n",
        "\n",
        "# divisão da amostra entre treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "      text_vect, \n",
        "      df[\"categoria\"], \n",
        "      test_size = 0.2, \n",
        "      random_state = 42\n",
        "  )\n",
        "\n",
        "# treinamento do modelo ávore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "y_prediction = tree.predict(X_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "accuracy = accuracy_score(y_prediction, y_test)\n",
        "\n",
        "print(text_vect.shape)\n",
        "print(accuracy)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "(1424, 100086)\n",
            "0.9578947368421052\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGTuFeHdMLCX",
        "colab_type": "code",
        "outputId": "10154b47-3a0e-4752-aa4e-da8ac7376ad4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Exemplo 5: Vetorização por contagem de termos TF-IDF com a combinação de unigrama com documentos lematizado, sem stopwords do SpaCy e NLTK combinadas e modelo de classificação DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import spacy\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nlp = spacy.load('pt')\n",
        "\n",
        "# stopwords do SpaCy e NLTK combinadas\n",
        "stops_spacy = nlp.Defaults.stop_words\n",
        "stops_nltk = nltk.corpus.stopwords.words('portuguese')\n",
        "stops = list(set(stops_spacy).union(set(stops_nltk)))\n",
        "\n",
        "# vetorização por contagem de termos no documento lematizado\n",
        "vetorTfidf = TfidfVectorizer(ngram_range=(1,1), use_idf=True, stop_words=stops, norm='l2') # exemplo 4.1: vetorização tf-idf e combinação de unigrama sem stopwords NLTK e Spacy\n",
        "#vetorTfidf = TfidfVectorizer(ngram_range=(1,2), use_idf=True, stop_words=stops_spacy, norm='l2') # exemplo 4.2: vetorização tf-idf e combinação de unigrama e bigrama sem stopwords NLTK e Spacy\n",
        "#vetorTfidf = TfidfVectorizer(ngram_range=(1,2), use_idf=False, stop_words=stops_spacy, norm='l1') # exemplo 4.3: vetorização tf e combinação de unigrama e bigrama sem stopwords NLTK e Spacy\n",
        "vetorTfidf.fit(df.text_lemma)\n",
        "text_vect = vetorTfidf.transform(df.text_lemma)\n",
        "\n",
        "# divisão da amostra entre treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "      text_vect, \n",
        "      df[\"categoria\"], \n",
        "      test_size = 0.2, \n",
        "      random_state = 42\n",
        "  )\n",
        "\n",
        "# treinamento do modelo ávore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "y_prediction = tree.predict(X_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "accuracy = accuracy_score(y_prediction, y_test)\n",
        "\n",
        "print(text_vect.shape)\n",
        "print(accuracy)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "(1424, 19961)\n",
            "0.9614035087719298\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bC8VbMbL2Lou",
        "colab_type": "code",
        "outputId": "d4c35cbf-918b-49f9-cbfe-f94d443756c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Exemplo 6: Vetorização por contagem de termos TF-IDF com a combinação de unigrama com documentos com verbos lematizado, sem stopwords do SpaCy e NLTK combinadas e modelo de classificação Regressão Logistica\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import spacy\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nlp = spacy.load('pt')\n",
        "\n",
        "# stopwords do SpaCy e NLTK combinadas\n",
        "stops_spacy = nlp.Defaults.stop_words\n",
        "stops_nltk = nltk.corpus.stopwords.words('portuguese')\n",
        "stops = list(set(stops_spacy).union(set(stops_nltk)))\n",
        "\n",
        "# vetorização por contagem de termos no documento lematizado\n",
        "vetorTfidf = TfidfVectorizer(ngram_range=(1,1), use_idf=True, stop_words=stops, norm='l2')\n",
        "vetorTfidf.fit(df.text_lemma_verbs)\n",
        "text_vect = vetorTfidf.transform(df.text_lemma_verbs)\n",
        "\n",
        "# treinamento do modelo ávore de decisão\n",
        "model = LogisticRegression(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "y_prediction = model.predict(X_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "accuracy = accuracy_score(y_prediction, y_test)\n",
        "\n",
        "print(text_vect.shape)\n",
        "print(accuracy)\n",
        "\n",
        "# Nosso melhor modelo até aqui!!! :)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "(1424, 21436)\n",
            "0.9649122807017544\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}