{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a2BT_ZwvhEKF"
   },
   "source": [
    "## Carregando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "MbxTY0CHaaDl",
    "outputId": "046b13af-0825-4d42-9bfb-c454cd3b9623"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nome</th>\n",
       "      <th>descricao</th>\n",
       "      <th>categoria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4080</td>\n",
       "      <td>2916</td>\n",
       "      <td>4080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3696</td>\n",
       "      <td>2460</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Boneco Dragon Ball Z Son Gokou</td>\n",
       "      <td>JOGO ORIGINAL. NOVO. LACRADO. PRONTA ENTREGA. ...</td>\n",
       "      <td>livro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     nome  ... categoria\n",
       "count                                4080  ...      4080\n",
       "unique                               3696  ...         4\n",
       "top      Boneco Dragon Ball Z Son Gokou    ...     livro\n",
       "freq                                   20  ...      1020\n",
       "\n",
       "[4 rows x 3 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"https://dados-ml-pln.s3-sa-east-1.amazonaws.com/produtos.csv\", delimiter=\";\", encoding='utf-8')\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bzdJoltLsMnT",
    "outputId": "eb091b56-27b4-4ac9-c3b5-bce64ce9ca7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2916, 3)"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True) # exclui registros com valores faltantes no própro objeto. inplace=False retorna uma cópia sem alterar o objeto.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3b1AsI8DhJN3"
   },
   "source": [
    "## Criar uma nova coluna Nome + Descrição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "C0vbmpsTZ7w2",
    "outputId": "7db18af9-af7b-4ae7-e78d-fc207fa1c303"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AndersonDourado\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de concateção de informações\n",
    "print(\"Anderson\" + \"Dourado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "5naO2LQHb8c-",
    "outputId": "5ab0ff84-fd4b-4156-e549-d674b0829aca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' O Hobbit - 7ª Ed. 2013  Produto NovoBilbo Bolseiro é um hobbit que leva uma vida confortável e sem ambições. Mas seu contentamento é perturbado quando Gandalf, o mago, e uma companhia de anões batem à sua porta e levam-no para uma expedição. Eles têm um plano para roubar o tesouro guardado por Smaug, o Magnífico, um grande e perigoso dragão. Bilbo reluta muito em participar da aventura, mas acaba surpreendendo até a si mesmo com sua esperteza e sua habilidade como ladrão!CaracterísticasAutor: Tolkien, J. R. R.Peso: 0.44I.S.B.N.: 9788578277109Altura: 20.000000Largura: 13.000000Profundidade: 1.000000Número de Páginas: 328Idioma: PortuguêsAcabamento: BrochuraNúmero da edição: 7Ano da edição: 2013'"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"texto\"] = df['nome'] + \" \" + df['descricao'] # cria uma nova culuna com os valores concatenados\n",
    "df.texto[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eok0vq2diIFa"
   },
   "source": [
    "## Quantos Unigramas existem antes e depois de remover stopwords?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "rAz1ZRXwtag-",
    "outputId": "bffa1c8c-2469-4208-ad4d-88cf4ba73acf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "d7EsxlE8gzY0",
    "outputId": "a68396cb-6f0d-4300-b230-3ef9d36c77bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIGRAMAS com STOPWORDS 35466\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer # Converte uma coleção de documentos de texto em uma matriz de contagens de tokens\n",
    "\n",
    "vect = CountVectorizer(ngram_range=(1,1))\n",
    "vect.fit(df.texto)\n",
    "text_vect = vect.transform(df.texto)\n",
    "\n",
    "print('UNIGRAMAS com STOPWORDS', text_vect.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "x39IfAib6DDk",
    "outputId": "0a960b67-d486-4734-c84f-778995696657"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2916, 35466)"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IxswZwj1sXV_",
    "outputId": "999d8235-0386-4d99-98ea-e05515f03bcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIGRAMAS sem STOPWORDS 35310\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "\n",
    "vect = CountVectorizer(ngram_range=(1,1), stop_words=stopwords)\n",
    "vect.fit(df.texto)\n",
    "text_vect = vect.transform(df.texto)\n",
    "\n",
    "print('UNIGRAMAS sem STOPWORDS', text_vect.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XTboWmwxtiXw"
   },
   "source": [
    "## Quantos Bigramas existem antes e depois de remover stopwords?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bVWal6nhtlRE",
    "outputId": "37e3dc1f-3ffc-40b8-e981-7b058d067d49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIGRAMAS com STOPWORDS 159553\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer(ngram_range=(2,2))\n",
    "vect.fit(df.texto)\n",
    "text_vect = vect.transform(df.texto)\n",
    "\n",
    "print('BIGRAMAS com STOPWORDS', text_vect.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "InldwDGxtlsd",
    "outputId": "46551582-a375-46b9-f7e0-0646758c1dfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIGRAMAS sem STOPWORDS 145409\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "\n",
    "vect = CountVectorizer(ngram_range=(2,2), stop_words=stopwords)\n",
    "vect.fit(df.texto)\n",
    "text_vect = vect.transform(df.texto)\n",
    "\n",
    "print('BIGRAMAS sem STOPWORDS', text_vect.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1O85EfGNtzhN"
   },
   "source": [
    "## Quantos Trigramas existem antes e depois de remover stopwords?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VM0puN6Jt67t",
    "outputId": "c81318bc-ff41-4bb3-923d-d2e18f8350fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIGRAMAS com STOPWORDS 228162\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer(ngram_range=(3,3))\n",
    "vect.fit(df.texto)\n",
    "text_vect = vect.transform(df.texto)\n",
    "\n",
    "print('TRIGRAMAS com STOPWORDS', text_vect.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DDfuZ3hht7Dh",
    "outputId": "56b4231c-6f12-4e44-8849-d9bda6d2231a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIGRAMAS sem STOPWORDS 177869\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "\n",
    "vect = CountVectorizer(ngram_range=(3,3), stop_words=stopwords)\n",
    "vect.fit(df.texto)\n",
    "text_vect = vect.transform(df.texto)\n",
    "\n",
    "print('TRIGRAMAS sem STOPWORDS', text_vect.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7hUJ2U3nj1xt"
   },
   "source": [
    "## Quantos verbos e adverbios existem na nova coluna?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "SWpgtWG0vKS0",
    "outputId": "200a8bee-4f2d-47a1-81a7-a9ee0dffae4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
      "[nltk_data]   Unzipping stemmers/rslp.zip.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('rslp')\n",
    "nltk.download('punkt')\n",
    "nltk.download('universal_tagset')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "Ij4J1taKd_DN",
    "outputId": "e969c6de-b047-4614-c89f-a5186997ba72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'Hobbit',\n",
       " '-',\n",
       " '7ª',\n",
       " 'Ed',\n",
       " '.',\n",
       " '2013',\n",
       " 'Produto',\n",
       " 'NovoBilbo',\n",
       " 'Bolseiro',\n",
       " 'é',\n",
       " 'um',\n",
       " 'hobbit',\n",
       " 'que']"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "word_tokenize('O Hobbit - 7ª Ed. 2013  Produto NovoBilbo Bolseiro é um hobbit que')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "id": "1Odl4b9aiOnA",
    "outputId": "e90208d7-8dcd-46b8-b0bb-2ec02ad40a76"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[O, Hobbit, -, 7ª, Ed, ., 2013, Produto, NovoB...</td>\n",
       "      <td>O Hobbit - 7ª Ed. 2013  Produto NovoBilbo Bol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Livro, -, It, A, Coisa, -, Stephen, King, Pro...</td>\n",
       "      <td>Livro - It A Coisa - Stephen King  Produto No...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens                                              texto\n",
       "0  [O, Hobbit, -, 7ª, Ed, ., 2013, Produto, NovoB...   O Hobbit - 7ª Ed. 2013  Produto NovoBilbo Bol...\n",
       "1  [Livro, -, It, A, Coisa, -, Stephen, King, Pro...   Livro - It A Coisa - Stephen King  Produto No..."
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens'] = df.texto.apply(word_tokenize) # aplica a tokenização no campo texto\n",
    "\n",
    "df[[\"tokens\",\"texto\"]].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OuyoJ0Gi1bGa"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "pd.set_option('display.max_colwidth', -1) # habilita a descrição completa do conteúdo das colunas\n",
    "df[[\"tokens\",\"texto\"]].head(2)\n",
    "\n",
    "pd.reset_option('display.max_colwidth')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "ohNe2lI6eBWv",
    "outputId": "707a7202-b0f8-4883-edb5-9427cc90be72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [(O, NOUN), (Hobbit, NOUN), (-, .), (7ª, NUM),...\n",
       "1    [(Livro, NOUN), (-, .), (It, PRON), (A, DET), ...\n",
       "2    [(Box, NOUN), (As, ADP), (Crônicas, NOUN), (De...\n",
       "3    [(Box, NOUN), (Harry, NOUN), (Potter, NOUN), (...\n",
       "4    [(Livro, NOUN), (Origem, NOUN), (-, .), (Dan, ...\n",
       "Name: tags, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tag import pos_tag\n",
    "\n",
    "df['tags'] = df.tokens.apply(pos_tag, tagset='universal')\n",
    "\n",
    "df.tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BUZnYjJ7fLUK",
    "outputId": "ae91d109-8f69-42fe-f372-0be2fd5537a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('O', 'NOUN'),\n",
       " ('Hobbit', 'NOUN'),\n",
       " ('-', '.'),\n",
       " ('7ª', 'NUM'),\n",
       " ('Ed', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('2013', 'NUM'),\n",
       " ('Produto', 'NOUN'),\n",
       " ('NovoBilbo', 'NOUN'),\n",
       " ('Bolseiro', 'NOUN'),\n",
       " ('é', 'NOUN'),\n",
       " ('um', 'ADJ'),\n",
       " ('hobbit', 'NOUN'),\n",
       " ('que', 'ADJ'),\n",
       " ('leva', 'NOUN'),\n",
       " ('uma', 'ADJ'),\n",
       " ('vida', 'NOUN'),\n",
       " ('confortável', 'NOUN'),\n",
       " ('e', 'NOUN'),\n",
       " ('sem', 'NOUN'),\n",
       " ('ambições', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('Mas', 'NOUN'),\n",
       " ('seu', 'VERB'),\n",
       " ('contentamento', 'ADJ'),\n",
       " ('é', 'NOUN'),\n",
       " ('perturbado', 'NOUN'),\n",
       " ('quando', 'NOUN'),\n",
       " ('Gandalf', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('o', 'NOUN'),\n",
       " ('mago', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('e', 'X'),\n",
       " ('uma', 'ADJ'),\n",
       " ('companhia', 'NOUN'),\n",
       " ('de', 'ADP'),\n",
       " ('anões', 'X'),\n",
       " ('batem', 'NOUN'),\n",
       " ('à', 'NOUN'),\n",
       " ('sua', 'NOUN'),\n",
       " ('porta', 'NOUN'),\n",
       " ('e', 'VERB'),\n",
       " ('levam-no', 'ADJ'),\n",
       " ('para', 'NOUN'),\n",
       " ('uma', 'ADJ'),\n",
       " ('expedição', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('Eles', 'NOUN'),\n",
       " ('têm', 'VERB'),\n",
       " ('um', 'ADJ'),\n",
       " ('plano', 'NOUN'),\n",
       " ('para', 'NOUN'),\n",
       " ('roubar', 'NOUN'),\n",
       " ('o', 'NOUN'),\n",
       " ('tesouro', 'NOUN'),\n",
       " ('guardado', 'NOUN'),\n",
       " ('por', 'NOUN'),\n",
       " ('Smaug', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('o', 'NOUN'),\n",
       " ('Magnífico', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('um', 'ADJ'),\n",
       " ('grande', 'NOUN'),\n",
       " ('e', 'NOUN'),\n",
       " ('perigoso', 'NOUN'),\n",
       " ('dragão', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('Bilbo', 'NOUN'),\n",
       " ('reluta', 'NOUN'),\n",
       " ('muito', 'NOUN'),\n",
       " ('em', 'NOUN'),\n",
       " ('participar', 'NOUN'),\n",
       " ('da', 'NOUN'),\n",
       " ('aventura', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('mas', 'X'),\n",
       " ('acaba', 'X'),\n",
       " ('surpreendendo', 'X'),\n",
       " ('até', 'X'),\n",
       " ('a', 'DET'),\n",
       " ('si', 'NOUN'),\n",
       " ('mesmo', 'NOUN'),\n",
       " ('com', 'NOUN'),\n",
       " ('sua', 'NOUN'),\n",
       " ('esperteza', 'NOUN'),\n",
       " ('e', 'NOUN'),\n",
       " ('sua', 'NOUN'),\n",
       " ('habilidade', 'VERB'),\n",
       " ('como', 'ADJ'),\n",
       " ('ladrão', 'NOUN'),\n",
       " ('!', '.'),\n",
       " ('CaracterísticasAutor', 'NOUN'),\n",
       " (':', '.'),\n",
       " ('Tolkien', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('J.', 'NOUN'),\n",
       " ('R.', 'NOUN'),\n",
       " ('R.Peso', 'NOUN'),\n",
       " (':', '.'),\n",
       " ('0.44I.S.B.N', 'NUM'),\n",
       " ('.', '.'),\n",
       " (':', '.'),\n",
       " ('9788578277109Altura', 'NUM'),\n",
       " (':', '.'),\n",
       " ('20.000000Largura', 'NUM'),\n",
       " (':', '.'),\n",
       " ('13.000000Profundidade', 'NUM'),\n",
       " (':', '.'),\n",
       " ('1.000000Número', 'NUM'),\n",
       " ('de', 'ADP'),\n",
       " ('Páginas', 'NOUN'),\n",
       " (':', '.'),\n",
       " ('328Idioma', 'NUM'),\n",
       " (':', '.'),\n",
       " ('PortuguêsAcabamento', 'NOUN'),\n",
       " (':', '.'),\n",
       " ('BrochuraNúmero', 'NOUN'),\n",
       " ('da', 'VERB'),\n",
       " ('edição', 'NOUN'),\n",
       " (':', '.'),\n",
       " ('7Ano', 'NUM'),\n",
       " ('da', 'NOUN'),\n",
       " ('edição', 'NOUN'),\n",
       " (':', '.'),\n",
       " ('2013', 'NUM')]"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tags[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8dl5TtRpfvKI",
    "outputId": "4ebae1ba-03f0-4ba2-c59c-45c78170f6a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'a': 2})"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "counter = Counter()\n",
    "\n",
    "counter['a'] += 2\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "TiHuebNkKoNL",
    "outputId": "4988fd3d-bc34-49af-b43f-70502d214a57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Livro', 'NOUN'), ('-', '.'), ('It', 'PRON'), ('A', 'DET'), ('Coisa', 'NOUN'), ('-', '.'), ('Stephen', 'NOUN'), ('King', 'NOUN'), ('Produto', 'NOUN'), ('NovoDurante', 'NOUN'), ('as', 'ADP'), ('férias', 'ADJ'), ('escolares', 'NOUN'), ('de', 'ADP'), ('1958', 'NUM'), (',', '.'), ('em', 'X'), ('Derry', 'NOUN'), (',', '.'), ('pacata', 'NOUN'), ('cidadezinha', 'NOUN'), ('do', 'VERB'), ('Maine', 'NOUN'), (',', '.'), ('Bill', 'NOUN'), (',', '.'), ('Richie', 'NOUN'), (',', '.'), ('Stan', 'NOUN'), (',', '.'), ('Mike', 'NOUN'), (',', '.'), ('Eddie', 'NOUN'), (',', '.'), ('Ben', 'NOUN'), ('e', 'VERB'), ('Beverly', 'NOUN'), ('aprenderam', 'NOUN'), ('o', 'NOUN'), ('real', 'ADJ'), ('sentido', 'NOUN'), ('da', 'NOUN'), ('amizade', 'NOUN'), (',', '.'), ('do', 'VERB'), ('amor', 'ADV'), (',', '.'), ('da', 'NOUN'), ('confiança', 'NOUN'), ('e', 'NOUN'), ('...', '.'), ('do', 'VERB'), ('medo', 'NOUN'), ('.', '.'), ('O', 'NOUN'), ('mais', 'VERB'), ('profundo', 'ADJ'), ('e', 'NOUN'), ('tenebroso', 'NOUN'), ('medo', 'NOUN'), ('.', '.'), ('Naquele', 'NOUN'), ('verão', 'NOUN'), (',', '.'), ('eles', 'VERB'), ('enfrentaram', 'X'), ('pela', 'NOUN'), ('primeira', 'NOUN'), ('vez', 'VERB'), ('a', 'DET'), ('Coisa', 'NOUN'), (',', '.'), ('um', 'ADJ'), ('ser', 'NOUN'), ('sobrenatural', 'ADJ'), ('e', 'NOUN'), ('maligno', 'NOUN'), ('que', 'NOUN'), ('deixou', 'NOUN'), ('terríveis', 'NOUN'), ('marcas', 'NOUN'), ('de', 'ADP'), ('sangue', 'X'), ('em', 'NOUN'), ('Derry', 'NOUN'), ('.', '.'), ('Quase', 'NOUN'), ('trinta', 'ADJ'), ('anos', 'NOUN'), ('depois', 'NOUN'), (',', '.'), ('os', 'ADJ'), ('amigos', 'NOUN'), ('voltam', 'NOUN'), ('a', 'DET'), ('se', 'ADJ'), ('encontrar', 'NOUN'), ('.', '.'), ('Uma', 'NOUN'), ('nova', 'ADJ'), ('onda', 'NOUN'), ('de', 'ADP'), ('terror', 'NOUN'), ('tomou', 'VERB'), ('a', 'DET'), ('pequena', 'NOUN'), ('cidade', 'NOUN'), ('.', '.'), ('Mike', 'NOUN'), ('Hanlon', 'NOUN'), (',', '.'), ('o', 'ADJ'), ('único', 'NOUN'), ('que', 'NOUN'), ('permanece', 'NOUN'), ('em', 'NOUN'), ('Derry', 'NOUN'), (',', '.'), ('dá', 'NOUN'), ('o', 'ADJ'), ('sinal', 'ADJ'), ('.', '.'), ('Precisam', 'NOUN'), ('unir', 'ADJ'), ('forças', 'NOUN'), ('novamente', 'NOUN'), ('.', '.'), ('A', 'DET'), ('Coisa', 'NOUN'), ('volta', 'NOUN'), ('a', 'DET'), ('atacar', 'NOUN'), ('e', 'NOUN'), ('eles', 'NOUN'), ('devem', 'VERB'), ('cumprir', 'VERB'), ('a', 'DET'), ('promessa', 'NOUN'), ('selada', 'NOUN'), ('com', 'NOUN'), ('sangue', 'NOUN'), ('que', 'NOUN'), ('fizeram', 'NOUN'), ('quando', 'NOUN'), ('crianças', 'NOUN'), ('.', '.'), ('Só', 'NOUN'), ('eles', 'VERB'), ('têm', 'VERB'), ('a', 'DET'), ('chave', 'NOUN'), ('do', 'NOUN'), ('enigma', 'NOUN'), ('.', '.'), ('Só', 'NOUN'), ('eles', 'VERB'), ('sabem', 'X'), ('o', 'ADJ'), ('que', 'NOUN'), ('se', 'NOUN'), ('esconde', 'NOUN'), ('nas', 'NOUN'), ('entranhas', 'X'), ('de', 'X'), ('Derry', 'NOUN'), ('.', '.'), ('O', 'NOUN'), ('tempo', 'ADJ'), ('é', 'NOUN'), ('curto', 'NOUN'), (',', '.'), ('mas', 'X'), ('somente', 'NOUN'), ('eles', 'NOUN'), ('podem', 'VERB'), ('vencer', 'ADP'), ('a', 'DET'), ('Coisa', 'NOUN'), ('.', '.'), ('Em', 'NOUN'), ('``', '.'), ('It', 'PRON'), ('-', '.'), ('A', 'DET'), ('Coisa', 'NOUN'), (\"''\", '.'), (',', '.'), ('clássico', 'X'), ('de', 'X'), ('Stephen', 'NOUN'), ('King', 'NOUN'), ('em', 'NOUN'), ('nova', 'NOUN'), ('edição', 'NOUN'), (',', '.'), ('os', 'ADJ'), ('amigos', 'NOUN'), ('irão', 'NOUN'), ('até', 'NOUN'), ('o', 'NOUN'), ('fim', 'NOUN'), (',', '.'), ('mesmo', 'NOUN'), ('que', 'NOUN'), ('isso', 'NOUN'), ('signifique', 'NOUN'), ('ultrapassar', 'ADJ'), ('os', 'ADJ'), ('próprios', 'NOUN'), ('limites.CaracterísticasAutor', 'NOUN'), (':', '.'), ('King', 'NOUN'), (',', '.'), ('StephenPeso', 'NOUN'), (':', '.'), ('1.44I.S.B.N', 'NUM'), ('.', '.'), (':', '.'), ('9788560280940Altura', 'NUM'), (':', '.'), ('23.000000Largura', 'NUM'), (':', '.'), ('15.000000Profundidade', 'NUM'), (':', '.'), ('5.300000Idioma', 'NUM'), (':', '.'), ('PortuguêsAcabamento', 'NOUN'), (':', '.'), ('0Tradutor', 'NUM'), (':', '.'), ('Winarski', 'NOUN'), (',', '.'), ('RegianeNúmero', 'NOUN'), ('da', 'VERB'), ('edição', 'NOUN'), (':', '.'), ('0País', 'NUM'), ('de', 'ADP'), ('Origem', 'NOUN'), (':', '.'), ('BrasilSegmento', 'NOUN'), (':', '.'), ('Ficção', 'NOUN'), ('-', '.'), ('Histórias', 'NOUN'), ('inquietantes', 'VERB'), ('-', '.'), ('Terror', 'NOUN')]\n",
      " \n",
      "word:  Livro  tag:  NOUN\n",
      "word:  -  tag:  .\n",
      "word:  It  tag:  PRON\n",
      "word:  A  tag:  DET\n",
      "word:  Coisa  tag:  NOUN\n"
     ]
    }
   ],
   "source": [
    "tags = df.tags[1]\n",
    "print(tags)\n",
    "print(\" \")\n",
    "\n",
    "for word, tag in tags[:5]:\n",
    "  print(\"word: \", word, \" tag: \", tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "12xzkR1zz3nC",
    "outputId": "9d08dea7-4c79-4456-d07c-3fbffd6c2d96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbos 41770\n",
      "Adjetivos 50788\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter()\n",
    "\n",
    "for tags in df.tags:\n",
    "  for word, tag in tags:\n",
    "    counter[tag] += 1\n",
    "\n",
    "print('Verbos', counter.get('VERB'))\n",
    "print('Adjetivos', counter.get('ADJ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CLvw-MU-hSv4"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# para quem quiser entender como funciona a lógica, segue a mesma lógica usando print para mapear os passos\n",
    "from collections import Counter\n",
    "counter = Counter()\n",
    "for tags in df.tags:\n",
    "  print(\"tags: \", tags)\n",
    "  for word, tag in tags:\n",
    "    counter[tag] += 1\n",
    "    print(\"word: \", word, \" tag: \", tag)\n",
    "print('Verbos', counter.get('VERB'))\n",
    "print('Adjetivos', counter.get('ADJ'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5kuPtf4ME7ks",
    "outputId": "5d7c1ecd-d055-4f22-c56c-12922f1a1267"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "357181"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.get('NOUN') # SUBSTANTIVO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "N-w3pk50Ogl_",
    "outputId": "079c2d24-b760-472b-8036-a6df2b1b2ee1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'.': 89103,\n",
       "         'ADJ': 50788,\n",
       "         'ADP': 18205,\n",
       "         'ADV': 3652,\n",
       "         'CONJ': 1189,\n",
       "         'DET': 15421,\n",
       "         'NOUN': 357181,\n",
       "         'NUM': 24064,\n",
       "         'PRON': 282,\n",
       "         'PRT': 1824,\n",
       "         'VERB': 41770,\n",
       "         'X': 38967})"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oh60rZ8NIijA"
   },
   "source": [
    "De/Para do POS Tag com o tagset='universal':\n",
    "\n",
    "- NOUN (nouns / substantivos)\n",
    "- VERB (verbs / verbos)\n",
    "- ADJ (adjectives / adjetivos)\n",
    "- ADV (adverbs / advérbios)\n",
    "- PRON (pronouns / pronomes)\n",
    "- DET (determiners and articles / determinantes e artigos)\n",
    "- ADP (prepositions and postpositions / preposições e postposições)\n",
    "- NUM (numerals / numerais)\n",
    "- CONJ (conjunctions / conjunções)\n",
    "- PRT (particles / partículas)\n",
    "- . (punctuation marks / sinais de pontuação)\n",
    "- X (a catch-all for other categories such as abbreviations or foreign words / um exemplo geral para outras categorias, como abreviações ou palavras estrangeiras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T7fb6Jn85F9F"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lRICVTAt5F56"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bVDjrt-eT4MV"
   },
   "source": [
    "## Aplicar Stemmer em uma frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "HBJ-oLU9T3jT",
    "outputId": "abb96971-a067-4c28-8ae6-a91b092c43d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PorterStemmer: O \t\t RSLPStemmer: o\n",
      "PorterStemmer: hobbit \t\t RSLPStemmer: hobbit\n",
      "PorterStemmer: - \t\t RSLPStemmer: -\n",
      "PorterStemmer: 7ª \t\t RSLPStemmer: 7ª\n",
      "PorterStemmer: Ed \t\t RSLPStemmer: ed\n",
      "PorterStemmer: . \t\t RSLPStemmer: .\n",
      "PorterStemmer: 2013 \t\t RSLPStemmer: 2013\n",
      "PorterStemmer: produto \t\t RSLPStemmer: produt\n",
      "PorterStemmer: novobilbo \t\t RSLPStemmer: novobilb\n",
      "PorterStemmer: bolseiro \t\t RSLPStemmer: bols\n",
      "PorterStemmer: é \t\t RSLPStemmer: é\n",
      "PorterStemmer: um \t\t RSLPStemmer: um\n",
      "PorterStemmer: hobbit \t\t RSLPStemmer: hobbit\n",
      "PorterStemmer: que \t\t RSLPStemmer: que\n",
      "PorterStemmer: leva \t\t RSLPStemmer: lev\n",
      "PorterStemmer: uma \t\t RSLPStemmer: uma\n",
      "PorterStemmer: vida \t\t RSLPStemmer: vid\n",
      "PorterStemmer: confortável \t\t RSLPStemmer: confort\n",
      "PorterStemmer: e \t\t RSLPStemmer: e\n",
      "PorterStemmer: sem \t\t RSLPStemmer: sem\n",
      "PorterStemmer: ambiçõ \t\t RSLPStemmer: amb\n",
      "PorterStemmer: . \t\t RSLPStemmer: .\n",
      "PorterStemmer: ma \t\t RSLPStemmer: mas\n",
      "PorterStemmer: seu \t\t RSLPStemmer: seu\n",
      "PorterStemmer: contentamento \t\t RSLPStemmer: content\n",
      "PorterStemmer: é \t\t RSLPStemmer: é\n",
      "PorterStemmer: perturbado \t\t RSLPStemmer: perturb\n",
      "PorterStemmer: quando \t\t RSLPStemmer: qu\n",
      "PorterStemmer: gandalf \t\t RSLPStemmer: gandalf\n",
      "PorterStemmer: , \t\t RSLPStemmer: ,\n",
      "PorterStemmer: o \t\t RSLPStemmer: o\n",
      "PorterStemmer: mago \t\t RSLPStemmer: mag\n",
      "PorterStemmer: , \t\t RSLPStemmer: ,\n",
      "PorterStemmer: e \t\t RSLPStemmer: e\n",
      "PorterStemmer: uma \t\t RSLPStemmer: uma\n",
      "PorterStemmer: companhia \t\t RSLPStemmer: companh\n",
      "PorterStemmer: de \t\t RSLPStemmer: de\n",
      "PorterStemmer: anõ \t\t RSLPStemmer: anõ\n",
      "PorterStemmer: batem \t\t RSLPStemmer: bat\n",
      "PorterStemmer: à \t\t RSLPStemmer: à\n",
      "PorterStemmer: sua \t\t RSLPStemmer: sua\n",
      "PorterStemmer: porta \t\t RSLPStemmer: port\n",
      "PorterStemmer: e \t\t RSLPStemmer: e\n",
      "PorterStemmer: levam-no \t\t RSLPStemmer: levam-n\n",
      "PorterStemmer: para \t\t RSLPStemmer: par\n",
      "PorterStemmer: uma \t\t RSLPStemmer: uma\n",
      "PorterStemmer: expedição \t\t RSLPStemmer: exped\n",
      "PorterStemmer: . \t\t RSLPStemmer: .\n",
      "PorterStemmer: ele \t\t RSLPStemmer: ele\n",
      "PorterStemmer: têm \t\t RSLPStemmer: têm\n",
      "PorterStemmer: um \t\t RSLPStemmer: um\n",
      "PorterStemmer: plano \t\t RSLPStemmer: plan\n",
      "PorterStemmer: para \t\t RSLPStemmer: par\n",
      "PorterStemmer: roubar \t\t RSLPStemmer: roub\n",
      "PorterStemmer: o \t\t RSLPStemmer: o\n",
      "PorterStemmer: tesouro \t\t RSLPStemmer: tesour\n",
      "PorterStemmer: guardado \t\t RSLPStemmer: guard\n",
      "PorterStemmer: por \t\t RSLPStemmer: por\n",
      "PorterStemmer: smaug \t\t RSLPStemmer: smaug\n",
      "PorterStemmer: , \t\t RSLPStemmer: ,\n",
      "PorterStemmer: o \t\t RSLPStemmer: o\n",
      "PorterStemmer: magnífico \t\t RSLPStemmer: magníf\n",
      "PorterStemmer: , \t\t RSLPStemmer: ,\n",
      "PorterStemmer: um \t\t RSLPStemmer: um\n",
      "PorterStemmer: grand \t\t RSLPStemmer: grand\n",
      "PorterStemmer: e \t\t RSLPStemmer: e\n",
      "PorterStemmer: perigoso \t\t RSLPStemmer: perig\n",
      "PorterStemmer: dragão \t\t RSLPStemmer: drag\n",
      "PorterStemmer: . \t\t RSLPStemmer: .\n",
      "PorterStemmer: bilbo \t\t RSLPStemmer: bilb\n",
      "PorterStemmer: reluta \t\t RSLPStemmer: relut\n",
      "PorterStemmer: muito \t\t RSLPStemmer: muit\n",
      "PorterStemmer: em \t\t RSLPStemmer: em\n",
      "PorterStemmer: participar \t\t RSLPStemmer: particip\n",
      "PorterStemmer: da \t\t RSLPStemmer: da\n",
      "PorterStemmer: aventura \t\t RSLPStemmer: avent\n",
      "PorterStemmer: , \t\t RSLPStemmer: ,\n",
      "PorterStemmer: ma \t\t RSLPStemmer: mas\n",
      "PorterStemmer: acaba \t\t RSLPStemmer: acab\n",
      "PorterStemmer: surpreendendo \t\t RSLPStemmer: surpreend\n",
      "PorterStemmer: até \t\t RSLPStemmer: até\n",
      "PorterStemmer: a \t\t RSLPStemmer: a\n",
      "PorterStemmer: si \t\t RSLPStemmer: si\n",
      "PorterStemmer: mesmo \t\t RSLPStemmer: mesm\n",
      "PorterStemmer: com \t\t RSLPStemmer: com\n",
      "PorterStemmer: sua \t\t RSLPStemmer: sua\n",
      "PorterStemmer: esperteza \t\t RSLPStemmer: espert\n",
      "PorterStemmer: e \t\t RSLPStemmer: e\n",
      "PorterStemmer: sua \t\t RSLPStemmer: sua\n",
      "PorterStemmer: habilidad \t\t RSLPStemmer: habil\n",
      "PorterStemmer: como \t\t RSLPStemmer: com\n",
      "PorterStemmer: ladrão \t\t RSLPStemmer: ladr\n",
      "PorterStemmer: ! \t\t RSLPStemmer: !\n",
      "PorterStemmer: característicasautor \t\t RSLPStemmer: característicasau\n",
      "PorterStemmer: : \t\t RSLPStemmer: :\n",
      "PorterStemmer: tolkien \t\t RSLPStemmer: tolkien\n",
      "PorterStemmer: , \t\t RSLPStemmer: ,\n",
      "PorterStemmer: J. \t\t RSLPStemmer: j.\n",
      "PorterStemmer: R. \t\t RSLPStemmer: r.\n",
      "PorterStemmer: r.peso \t\t RSLPStemmer: r.pes\n",
      "PorterStemmer: : \t\t RSLPStemmer: :\n",
      "PorterStemmer: 0.44i.s.b.n \t\t RSLPStemmer: 0.44i.s.b.n\n",
      "PorterStemmer: . \t\t RSLPStemmer: .\n",
      "PorterStemmer: : \t\t RSLPStemmer: :\n",
      "PorterStemmer: 9788578277109altura \t\t RSLPStemmer: 9788578277109alt\n",
      "PorterStemmer: : \t\t RSLPStemmer: :\n",
      "PorterStemmer: 20.000000largura \t\t RSLPStemmer: 20.000000larg\n",
      "PorterStemmer: : \t\t RSLPStemmer: :\n",
      "PorterStemmer: 13.000000profundidad \t\t RSLPStemmer: 13.000000profund\n",
      "PorterStemmer: : \t\t RSLPStemmer: :\n",
      "PorterStemmer: 1.000000número \t\t RSLPStemmer: 1.000000númer\n",
      "PorterStemmer: de \t\t RSLPStemmer: de\n",
      "PorterStemmer: página \t\t RSLPStemmer: págin\n",
      "PorterStemmer: : \t\t RSLPStemmer: :\n",
      "PorterStemmer: 328idioma \t\t RSLPStemmer: 328idiom\n",
      "PorterStemmer: : \t\t RSLPStemmer: :\n",
      "PorterStemmer: portuguêsacabamento \t\t RSLPStemmer: portuguêsacab\n",
      "PorterStemmer: : \t\t RSLPStemmer: :\n",
      "PorterStemmer: brochuranúmero \t\t RSLPStemmer: brochuranúmer\n",
      "PorterStemmer: da \t\t RSLPStemmer: da\n",
      "PorterStemmer: edição \t\t RSLPStemmer: ediç\n",
      "PorterStemmer: : \t\t RSLPStemmer: :\n",
      "PorterStemmer: 7ano \t\t RSLPStemmer: 7an\n",
      "PorterStemmer: da \t\t RSLPStemmer: da\n",
      "PorterStemmer: edição \t\t RSLPStemmer: ediç\n",
      "PorterStemmer: : \t\t RSLPStemmer: :\n",
      "PorterStemmer: 2013 \t\t RSLPStemmer: 2013\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.rslp import RSLPStemmer\n",
    "\n",
    "tokens = df.tokens[0]\n",
    "\n",
    "ps = PorterStemmer()\n",
    "rslp = RSLPStemmer()\n",
    "\n",
    "for tok in tokens:\n",
    "  print('PorterStemmer: %s \\t\\t RSLPStemmer: %s' % (ps.stem(tok), rslp.stem(tok)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zhTMo3h0oFA7"
   },
   "source": [
    "## Quantos unigramas existem após aplicar Stemmer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YlUI2NgDhufq",
    "outputId": "70b8bc23-3358-4a89-87d6-493dddb9f8a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Anderson,Dourado'"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "','.join(['Anderson', 'Dourado'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "k_3LR9sO0hRm",
    "outputId": "a687a681-adb6-498e-b0c6-d6f894815afd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    o hobbit - 7ª ed . 2013 produt novobilb bols é...\n",
       "1    livr - it a cois - stephen king produt novodur...\n",
       "2    box as crôn de gel e fog pocket 5 livr produt ...\n",
       "3    box harry pott produt nov e físic a séri harry...\n",
       "4    livr orig - dan brown produt novod ond vi ? pa...\n",
       "Name: stemmer, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.rslp import RSLPStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "rslp = RSLPStemmer()\n",
    "\n",
    "def stem_pandas(line):\n",
    "  return ' '.join([rslp.stem(token) for token in line])\n",
    "\n",
    "df['stemmer'] = df.tokens.apply(stem_pandas)\n",
    "\n",
    "df.stemmer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NFiA2cAORmpc",
    "outputId": "cbc81e6c-3c67-4ec8-ebe3-21330026df8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIGRAMAS sem STOPWORDS 26528\n"
     ]
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "vect = CountVectorizer(ngram_range=(1,1), stop_words=stopwords)\n",
    "vect.fit(df.stemmer)\n",
    "\n",
    "text_vect = vect.transform(df.stemmer)\n",
    "\n",
    "print('UNIGRAMAS sem STOPWORDS', text_vect.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9QGwgdjvSW7L"
   },
   "source": [
    "NLTK = Natural Language Tool Kit\n",
    "\n",
    "RSLP = Removedor de Sulfixos da Língua Portuguesa\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Aula 1.2 IA PLN - Exercício.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
