{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ont8JX9spNZz"
   },
   "source": [
    "# **NLTK**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "colab_type": "code",
    "id": "MtRjU5tRYZQ3",
    "outputId": "bc433623-50f2-41d4-b6b9-3c9ab09b2f4c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\BRJUVEN1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Não',\n",
       " 'sei',\n",
       " 'se',\n",
       " 'entendi',\n",
       " 'como',\n",
       " 'ler',\n",
       " 'o',\n",
       " 'conteúdo',\n",
       " 'da',\n",
       " 'view',\n",
       " ',',\n",
       " 'então',\n",
       " '.',\n",
       " 'Estou',\n",
       " 'entendendo',\n",
       " 'que',\n",
       " 'a',\n",
       " 'view',\n",
       " 'contém',\n",
       " 'um',\n",
       " 'histórico',\n",
       " 'das',\n",
       " 'movimentações',\n",
       " 'dos',\n",
       " 'associados',\n",
       " ',',\n",
       " 'certo',\n",
       " '?']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk import tokenize\n",
    "\n",
    "texto_exemplo = \"Não sei se entendi como ler o conteúdo da view, então. \\\n",
    "Estou entendendo que a view contém um histórico das movimentações \\\n",
    "dos associados, certo?\"\n",
    "\n",
    "# Exemplo tokenização\n",
    "tokenize.word_tokenize(texto_exemplo, language=\"portuguese\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ReDnaw00nJid"
   },
   "source": [
    "Documentação nltk.tokenize: https://www.nltk.org/api/nltk.tokenize.html\n",
    "\n",
    "Exemplos em português: http://www.nltk.org/howto/portuguese_en.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jPHAfEYkVp-f"
   },
   "source": [
    "POS-Tagger NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "colab_type": "code",
    "id": "HNORsKEaTbFP",
    "outputId": "dcc0230c-1c74-4d26-da23-1b6654e7ded4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\BRJUVEN1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\BRJUVEN1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\BRJUVEN1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\universal_tagset.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('O', 'NOUN'),\n",
       " ('Hobbit', 'NOUN'),\n",
       " ('-', '.'),\n",
       " ('7ª', 'NUM'),\n",
       " ('Ed.', 'ADJ'),\n",
       " ('2013', 'NUM'),\n",
       " ('Produto', 'NOUN'),\n",
       " ('NovoBilbo', 'NOUN'),\n",
       " ('Bolseiro', 'NOUN'),\n",
       " ('é', 'NOUN'),\n",
       " ('um', 'ADJ'),\n",
       " ('hobbit', 'NOUN'),\n",
       " ('que', 'NOUN')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('universal_tagset')\n",
    "\n",
    "pos_tag(word_tokenize('O Hobbit - 7ª Ed. 2013  Produto NovoBilbo Bolseiro é um hobbit que', language=\"portuguese\"), tagset='universal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PGbw2K4UTdon"
   },
   "source": [
    "# **Sobre o corpus Floresta**\n",
    "\n",
    "---\n",
    "Conhecido como \"Floresta Sintática\". Conjunto de frases já analisadas sintáticamente e tageadas.\n",
    "\n",
    "https://www.linguateca.pt/Floresta/\n",
    "\n",
    "https://www.linguateca.pt/floresta/doc/VISLsymbolset-manual.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "kySnyrT1c1sy",
    "outputId": "79b00cc7-5af3-460b-b28b-6a0f6f308998"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package floresta to\n",
      "[nltk_data]     C:\\Users\\BRJUVEN1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\floresta.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import floresta\n",
    "import nltk\n",
    "nltk.download('floresta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "9mE1kjHprAkR",
    "outputId": "7fea104e-c34c-46a7-e728-21aa28f366e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portuguese Treebank\n",
      "\n",
      "Projecto Floresta Sinta(c)tica -- http://www.linguateca.pt/Floresta/\n",
      "Version 7.4  Distributed with permission.\n",
      "\n",
      "Penn Treebank format, available from http://linguateca.di.uminho.pt/FS/fs.html\n",
      "\n",
      "Key to tags (http://visl.sdu.dk/visl/pt/portsymbol.html)\n",
      "\n",
      "<ACC          direct object\n",
      "<ACC-PASS     passive use of pronoun 'se'\n",
      "<ADVS, <ADVO  adverbial argument\n",
      "<ADVL         adjunct adverbial\n",
      "<DAT          dative (indirect) object\n",
      "<FOC          focus marker (or right focus bracket)\n",
      "<OC           object complement\n",
      "<PASS         agent of passive\n",
      "<PIV          prepositional object\n",
      "<PRED         free (subject) predicative, right of main verb\n",
      "<SC           subject complement\n",
      "<SUBJ         subject\n",
      ">A            adverbial pre-adject (intensifier before adjective, adverb, pronoun or participle)\n",
      ">N            prenominal modifier\n",
      ">P            modifier of prepositional phrase (intensifier, operator or focus adverb)\n",
      ">S            modifier of clause (intensifier, operator or focus adverb)\n",
      "A<            adverbial post-adject (modifier or argument of adjective, adverb or participle)\n",
      "A<ADV         adverbial argument of attributive participle\n",
      "A<ADVL        adverbial adjunct of attributive participle\n",
      "A<PASS        agent of passive after attributive participle\n",
      "A<PIV         prepositional object of attributive participle\n",
      "A<SC          subject complement of attributive participle\n",
      "ACC>          accusative (direct) object\n",
      "ACC>-PASS     passive use of pronoun 'se'\n",
      "ACC>>         double-fronted accusative (direct) object before matrix verb\n",
      "ADVS>, ADVO>  adverbial argument\n",
      "ADVL          top node adverbial\n",
      "ADVL>         adjunct adverbial\n",
      "ADVL>A        adjunct adverbial before attributive participle\n",
      "ADVL>AS<      adjunct adverbial in averbal clause\n",
      "APP           identifying apposition\n",
      "AS<           clause body of averbal clause\n",
      "CO            co-ordinator\n",
      "COM           comparator (heading averbal clause)\n",
      "DAT>          dative (intransitive) object\n",
      "FAUX          finite auxiliary\n",
      "FMV           finite main verb\n",
      "FOC>          focus marker (or left focus bracket)\n",
      "IAUX          non-finite auxiliary\n",
      "IMV           non-finite main verb\n",
      "KOMP<         argument of comparative hook\n",
      "N<            postnominal modifier or argument\n",
      "N<PRED        postnominal (in-group) predicative (or non-identifying apposition)\n",
      "NPHR          top node noun phrase\n",
      "NUM<          second part of numeral chain\n",
      "OC>           object complement\n",
      "P<            argument of preposition\n",
      "PIV>          prepositional object\n",
      "PRD           predicator (heading averbal clause)\n",
      "PRED>         free (subject) predicative, left of main verb\n",
      "PREF          prefix (category being phased out)\n",
      "PRT-AUX<      auxiliary particle\n",
      "S<            statement predicative (sentence apposition)\n",
      "SC>           subject complement\n",
      "SUB           subordinator\n",
      "SUBJ>         subject\n",
      "SUBJ>>        double-fronted subject, with interfering matrix og quoting verb\n",
      "TOP           topic constituent\n",
      "VOK           vocative constituent\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(nltk.corpus.floresta.readme())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "dqcDbl4mdodH",
    "outputId": "c5c695d6-5388-4700-e351-9df482f87711"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Um', '>N+art'), ('revivalismo', 'H+n'), ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "floresta.tagged_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RbMcbwmoMoPU"
   },
   "source": [
    "As tags consistem em algumas informações sintáticas, seguidas por um sinal de mais, seguido por uma tag convencional de POS Tag com a classificação morfológica. Vamos retirar o material antes do sinal de mais (+):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "UVsS_hn0j1O5",
    "outputId": "ae86b45e-0ea4-480b-8df4-f1984f59be52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 212,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'+' in 'anderson dourado'\n",
    "\n",
    "'+' in 'anderson+dourado'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hjE63qXqoA5W"
   },
   "outputs": [],
   "source": [
    "# Função para simplificar a tag\n",
    "def simplifica_tag(t):\n",
    "  if \"+\" in t:\n",
    "    return t.split(\"+\")[1]\n",
    "  return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "j2SbIXeNmJf7",
    "outputId": "3bbc09d8-a609-491c-d155-41cec2131cbd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('um', 'art'),\n",
       " ('revivalismo', 'n'),\n",
       " ('refrescante', 'adj'),\n",
       " ('o', 'art'),\n",
       " ('7_e_meio', 'prop'),\n",
       " ('é', 'v-fin'),\n",
       " ('um', 'art'),\n",
       " ('ex-libris', 'n'),\n",
       " ('de', 'prp'),\n",
       " ('a', 'art'),\n",
       " ('noite', 'n'),\n",
       " ('algarvia', 'adj'),\n",
       " ('.', '.'),\n",
       " ('é', 'v-fin'),\n",
       " ('uma', 'num'),\n",
       " ('de', 'prp'),\n",
       " ('as', 'art'),\n",
       " ('mais', 'adv'),\n",
       " ('antigas', 'adj'),\n",
       " ('discotecas', 'n')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo 1\n",
    "tag_words = nltk.corpus.floresta.tagged_words() #type(twords)\n",
    "\n",
    "list_palavras = [] #type(list_palavras)\n",
    "tuple_dupla = () #type(tuple_dupla)\n",
    "\n",
    "for word, tag in tag_words:\n",
    "  tuple_dupla = (word.lower(), simplifica_tag(tag))\n",
    "  list_palavras.append(tuple_dupla)\n",
    "\n",
    "list_palavras[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "5D8P4BWEdq45",
    "outputId": "2e1afb0c-bdaf-4275-92c6-299f0eb1a3ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('um', 'art'),\n",
       " ('revivalismo', 'n'),\n",
       " ('refrescante', 'adj'),\n",
       " ('o', 'art'),\n",
       " ('7_e_meio', 'prop'),\n",
       " ('é', 'v-fin'),\n",
       " ('um', 'art'),\n",
       " ('ex-libris', 'n'),\n",
       " ('de', 'prp'),\n",
       " ('a', 'art')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo 2\n",
    "tag_words = nltk.corpus.floresta.tagged_words()\n",
    "tag_words\n",
    "\n",
    "tag_words = [(w.lower(),simplifica_tag(t)) for (w,t) in tag_words]\n",
    "\n",
    "tag_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9w3cHfOheAZ2"
   },
   "source": [
    "Exemplo de texto anotado (tagueado) no corpus Floresta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8U1EuM1jg_-I",
    "outputId": "483643dd-11d9-432a-abad-b40f57e90587"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "um/art revivalismo/n refrescante/adj o/art 7_e_meio/prop é/v-fin um/art ex-libris/n de/prp a/art\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(word + '/' + tag for (word, tag) in tag_words[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "FQQzXZP5pQ1z",
    "outputId": "1adeb423-1efa-40a6-bbd4-7c91aecd01e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Um', '>N+art'), ('revivalismo', 'H+n'), ('refrescante', 'N<+adj')],\n",
       " [('O', '>N+art'),\n",
       "  ('7_e_Meio', 'H+prop'),\n",
       "  ('é', 'P+v-fin'),\n",
       "  ('um', '>N+art'),\n",
       "  ('ex-libris', 'H+n'),\n",
       "  ('de', 'H+prp'),\n",
       "  ('a', '>N+art'),\n",
       "  ('noite', 'H+n'),\n",
       "  ('algarvia', 'N<+adj'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_sents = floresta.tagged_sents()\n",
    "tag_sents[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VCbf1QPT1InW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('um', 'art'), ('revivalismo', 'n'), ('refrescante', 'adj')],\n",
       " [('o', 'art'),\n",
       "  ('7_e_meio', 'prop'),\n",
       "  ('é', 'v-fin'),\n",
       "  ('um', 'art'),\n",
       "  ('ex-libris', 'n'),\n",
       "  ('de', 'prp'),\n",
       "  ('a', 'art'),\n",
       "  ('noite', 'n'),\n",
       "  ('algarvia', 'adj'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contagem das tags e mantendo a estruturas das sentenças do corpus floresta\n",
    "from nltk.corpus import floresta\n",
    "from collections import Counter\n",
    "\n",
    "def simplifica_tag(t):\n",
    "  if \"+\" in t:\n",
    "    return t.split(\"+\")[1]\n",
    "  return t \n",
    "\n",
    "counter = Counter()\n",
    "\n",
    "tag_sents = floresta.tagged_sents()\n",
    "tag_new_sents = []\n",
    "for sent in tag_sents:\n",
    "  new_sent = []\n",
    "  for (w,t) in sent:\n",
    "    tag = simplifica_tag(t)\n",
    "    new_sent.append((w.lower(), tag))\n",
    "    counter[tag] += 1\n",
    "  tag_new_sents.append(new_sent)\n",
    "\n",
    "new_sent\n",
    "tag_new_sents[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "nNmXhgOw1t7k",
    "outputId": "6472d1a1-d35b-4ff9-f2f7-5ebf2a0ad258"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('n', 40081), ('prp', 32442), ('art', 29360), ('v-fin', 15802), (',', 13444)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "r6mPWpv62Z0l",
    "outputId": "376d8741-1046-4ebb-d96f-4d13b9998ced"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18919339916545513"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# % dos substantivos\n",
    "counter.get('n') / sum(counter.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FpQ87t8fgAzX"
   },
   "source": [
    "Verificamos que a tag mais comum é N. Essa será nossa referência a tag padrão (gold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "colab_type": "code",
    "id": "oKnTSb5Z7uBI",
    "outputId": "2974bd99-6232-49e1-ace5-585f02638510"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Não', 'n'),\n",
       " ('sei', 'n'),\n",
       " ('se', 'n'),\n",
       " ('entendi', 'n'),\n",
       " ('como', 'n'),\n",
       " ('ler', 'n'),\n",
       " ('o', 'n'),\n",
       " ('conteúdo', 'n'),\n",
       " ('da', 'n'),\n",
       " ('view', 'n'),\n",
       " (',', 'n'),\n",
       " ('então', 'n'),\n",
       " ('.', 'n'),\n",
       " ('Estou', 'n'),\n",
       " ('entendendo', 'n'),\n",
       " ('que', 'n'),\n",
       " ('a', 'n'),\n",
       " ('view', 'n'),\n",
       " ('contém', 'n'),\n",
       " ('um', 'n'),\n",
       " ('histórico', 'n'),\n",
       " ('das', 'n'),\n",
       " ('movimentações', 'n'),\n",
       " ('dos', 'n'),\n",
       " ('associados', 'n'),\n",
       " (',', 'n'),\n",
       " ('certo', 'n'),\n",
       " ('?', 'n')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crianto uma tag default\n",
    "default_tagger = nltk.DefaultTagger('n')\n",
    "\n",
    "token_texto_exemplo = tokenize.word_tokenize(texto_exemplo, language=\"portuguese\")\n",
    "default_tagger.tag(token_texto_exemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "WZf9bpKwACxK",
    "outputId": "fcf1bd7f-7ea6-4591-80ab-5f3cecc2a75a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18919339916545513\n"
     ]
    }
   ],
   "source": [
    "# Analisando com base na tag padrão (tag ouro/gold)\n",
    "tag_sents = tag_new_sents\n",
    "\n",
    "default_tagger = nltk.DefaultTagger('n')\n",
    "print(default_tagger.evaluate(tag_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "er6gXU5IhTkM",
    "outputId": "009bd868-7d1b-4fdb-931e-538e1550dbe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17800040072129833\n",
      "0.8740532959326788\n",
      "0.8900420757363254\n",
      "0.8887998397114807\n"
     ]
    }
   ],
   "source": [
    "tag_sents = tag_new_sents\n",
    "#type(tag_sents) #len(tag_sents)\n",
    "#tag_sents[len(tag_sents)-1] #tag_sents[-1]\n",
    "\n",
    "tag_sents_treino = tag_sents[1000:]\n",
    "tag_sents_teste = tag_sents[:1000]\n",
    "\n",
    "tagger0 = nltk.DefaultTagger('n')\n",
    "print(tagger0.evaluate(tag_sents_teste))\n",
    "\n",
    "tagger1 = nltk.UnigramTagger(tag_sents_treino, backoff=tagger0)\n",
    "print(tagger1.evaluate(tag_sents_teste))\n",
    "\n",
    "tagger2 = nltk.BigramTagger(tag_sents_treino, backoff=tagger1)\n",
    "print(tagger2.evaluate(tag_sents_teste))\n",
    "\n",
    "tagger3 = nltk.TrigramTagger(tag_sents_treino, backoff=tagger2)\n",
    "print(tagger3.evaluate(tag_sents_teste))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5e4lHBKC9xUB"
   },
   "source": [
    "\n",
    "Documentação dos métodos tag:\n",
    "  - https://www.nltk.org/api/nltk.tag.html\n",
    "\n",
    "Nos baseamos no métodos da documentação abaixo:\n",
    "  - Capítulo 5 - N-Gram Tagging: http://www.nltk.org/book/ch05.html\n",
    "  - Exemplo em português: http://www.nltk.org/howto/portuguese_en.html\n",
    "  - Outros corpus tageados: https://www.nltk.org/book/ch02.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ZAe-S-errcNR",
    "outputId": "85840dd2-8c3d-4101-ef3e-237af70a6bd2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tagger.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(tagger3, 'tagger.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "quA-JTPNOzcu",
    "outputId": "6f6ef43f-78eb-48ff-a229-8b7df380d1bc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "#Este é um comando do Linux para listar os diretórios (Não vai rodar no Windows, que seria um \"dir\")\n",
    "!ls -all -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RVCddXw7sVsa"
   },
   "outputs": [],
   "source": [
    "bla = joblib.load('tagger.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "OKiTgA9ysc0R",
    "outputId": "9894dc0a-69aa-4c60-82bf-d78eaea27fa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8887998397114807\n"
     ]
    }
   ],
   "source": [
    "print(bla.evaluate(tag_sents_teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "colab_type": "code",
    "id": "HmZdOuNCaV0j",
    "outputId": "161c305d-3dc3-4f69-f869-e7c5f935ea4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Não', 'n'),\n",
       " ('sei', 'v-fin'),\n",
       " ('se', 'pron-pers'),\n",
       " ('entendi', 'n'),\n",
       " ('como', 'adv'),\n",
       " ('ler', 'v-inf'),\n",
       " ('o', 'art'),\n",
       " ('conteúdo', 'n'),\n",
       " ('da', 'n'),\n",
       " ('view', 'n'),\n",
       " (',', ','),\n",
       " ('então', 'adv'),\n",
       " ('.', '.'),\n",
       " ('Estou', 'n'),\n",
       " ('entendendo', 'v-ger'),\n",
       " ('que', 'conj-s'),\n",
       " ('a', 'art'),\n",
       " ('view', 'n'),\n",
       " ('contém', 'n'),\n",
       " ('um', 'art'),\n",
       " ('histórico', 'adj'),\n",
       " ('das', 'n'),\n",
       " ('movimentações', 'n'),\n",
       " ('dos', 'prop'),\n",
       " ('associados', 'n'),\n",
       " (',', ','),\n",
       " ('certo', 'adj'),\n",
       " ('?', '?')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto_exemplo\n",
    "twords = tokenize.word_tokenize(texto_exemplo, language=\"portuguese\")\n",
    "bla.tag(twords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "colab_type": "code",
    "id": "fI-YYFYUjwIk",
    "outputId": "19ac1501-d8ed-49c4-cbaf-38347b2073b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Não', 'n'),\n",
       " ('sei', 'v-fin'),\n",
       " ('se', 'pron-pers'),\n",
       " ('entendi', 'n'),\n",
       " ('como', 'adv'),\n",
       " ('ler', 'v-inf'),\n",
       " ('o', 'art'),\n",
       " ('conteúdo', 'n'),\n",
       " ('da', 'n'),\n",
       " ('view', 'n'),\n",
       " (',', ','),\n",
       " ('então', 'adv'),\n",
       " ('.', '.'),\n",
       " ('Estou', 'n'),\n",
       " ('entendendo', 'v-ger'),\n",
       " ('que', 'conj-s'),\n",
       " ('a', 'art'),\n",
       " ('view', 'n'),\n",
       " ('contém', 'n'),\n",
       " ('um', 'art'),\n",
       " ('histórico', 'adj'),\n",
       " ('das', 'n'),\n",
       " ('movimentações', 'n'),\n",
       " ('dos', 'prop'),\n",
       " ('associados', 'n'),\n",
       " (',', ','),\n",
       " ('certo', 'adj'),\n",
       " ('?', '?')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#twords = tokenize.word_tokenize(texto_exemplo, language=\"portuguese\")\n",
    "tagger2.tag(twords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "colab_type": "code",
    "id": "9iIx3MhZkl-o",
    "outputId": "7bc11677-13ed-41a6-d2d9-97031cb9fb8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Não', 'n'),\n",
       " ('sei', 'v-fin'),\n",
       " ('se', 'pron-pers'),\n",
       " ('entendi', 'n'),\n",
       " ('como', 'adv'),\n",
       " ('ler', 'v-inf'),\n",
       " ('o', 'art'),\n",
       " ('conteúdo', 'n'),\n",
       " ('da', 'n'),\n",
       " ('view', 'n'),\n",
       " (',', ','),\n",
       " ('então', 'adv'),\n",
       " ('.', '.'),\n",
       " ('Estou', 'n'),\n",
       " ('entendendo', 'v-ger'),\n",
       " ('que', 'pron-indp'),\n",
       " ('a', 'art'),\n",
       " ('view', 'n'),\n",
       " ('contém', 'n'),\n",
       " ('um', 'art'),\n",
       " ('histórico', 'adj'),\n",
       " ('das', 'n'),\n",
       " ('movimentações', 'n'),\n",
       " ('dos', 'prop'),\n",
       " ('associados', 'n'),\n",
       " (',', ','),\n",
       " ('certo', 'adj'),\n",
       " ('?', '?')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger1.tag(twords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "colab_type": "code",
    "id": "inKncgHXouUe",
    "outputId": "7854cc7b-7332-40fe-9bbc-63a9e5f6fc23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portuguese Treebank\n",
      "\n",
      "Projecto Floresta Sinta(c)tica -- http://www.linguateca.pt/Floresta/\n",
      "Version 7.4  Distributed with permission.\n",
      "\n",
      "Penn Treebank format, available from http://linguateca.di.uminho.pt/FS/fs.html\n",
      "\n",
      "Key to tags (http://visl.sdu.dk/visl/pt/portsymbol.html)\n",
      "\n",
      "<ACC          direct object\n",
      "<ACC-PASS     passive use of pronoun 'se'\n",
      "<ADVS, <ADVO  adverbial argument\n",
      "<ADVL         adjunct adverbial\n",
      "<DAT          dative (indirect) object\n",
      "<FOC          focus marker (or right focus bracket)\n",
      "<OC           object complement\n",
      "<PASS         agent of passive\n",
      "<PIV          prepositional object\n",
      "<PRED         free (subject) predicative, right of main verb\n",
      "<SC           subject complement\n",
      "<SUBJ         subject\n",
      ">A            adverbial pre-adject (intensifier before adjective, adverb, pronoun or participle)\n",
      ">N            prenominal modifier\n",
      ">P            modifier of prepositional phrase (intensifier, operator or focus adverb)\n",
      ">S            modifier of clause (intensifier, operator or focus adverb\n"
     ]
    }
   ],
   "source": [
    "print(nltk.corpus.floresta.readme()[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WpdWBDZlWrDw"
   },
   "source": [
    "# **TextBlob**\n",
    "\n",
    "---\n",
    "\n",
    "O TextBlob já oferente uma seria de recursos de PLN, como: marcação POS-Tag, extração de frases substantivas, análise de sentimentos, classificação, tradução e outras.\n",
    "\n",
    "- Documentação oficial: https://textblob.readthedocs.io/en/dev/index.html\n",
    "- Natural Language Basics with TextBlob - Allison Parrish: http://rwet.decontextualize.com/book/textblob/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "_4kC31vdIlza",
    "outputId": "47743885-d16f-4071-9c8d-e229f7a6e724"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in /usr/local/lib/python3.6/dist-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.6/dist-packages (from textblob) (3.2.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "udjWzyToWuKb",
    "outputId": "397e1ba0-8920-4003-d819-edf2dd82bef0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\BRJUVEN1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\movie_reviews.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sentiment(classification='neg', p_pos=0.288629160063391, p_neg=0.7113708399366088)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "nltk.download('movie_reviews')\n",
    "\n",
    "opinion = TextBlob(\"batman vs superman is a shit!\", analyzer=NaiveBayesAnalyzer())\n",
    "opinion.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "WuKIO5dO5Mg5",
    "outputId": "34a77b76-b561-4926-c302-ebfe76fc4871"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\BRJUVEN1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "xM5jokbDglMJ",
    "outputId": "e70151e7-dcd2-4c75-c61a-3eb6848be8cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frase original:  Não sei se entendi como ler o conteúdo da view, então. Estou entendendo que a view contém um histórico das movimentações dos associados, certo?\n",
      "Idioma:  pt\n",
      "Traduzido:  I don't know if I understood how to read the contents of the view, then. I understand that the view contains a history of the members' movements, right?\n",
      "Tags:  [('I', 'PRP'), ('do', 'VBP'), (\"n't\", 'RB'), ('know', 'VB'), ('if', 'IN'), ('I', 'PRP'), ('understood', 'VBD'), ('how', 'WRB'), ('to', 'TO'), ('read', 'VB'), ('the', 'DT'), ('contents', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('view', 'NN'), ('then', 'RB'), ('I', 'PRP'), ('understand', 'VBP'), ('that', 'IN'), ('the', 'DT'), ('view', 'NN'), ('contains', 'VBZ'), ('a', 'DT'), ('history', 'NN'), ('of', 'IN'), ('the', 'DT'), ('members', 'NNS'), (\"'\", 'POS'), ('movements', 'NNS'), ('right', 'RB')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Frase original: \", texto_exemplo)\n",
    "\n",
    "tblob = TextBlob(texto_exemplo)\n",
    "\n",
    "print('Idioma: ',tblob.detect_language())\n",
    "\n",
    "en_tblob = tblob.translate(to='en')\n",
    "\n",
    "print(\"Traduzido: \", en_tblob)\n",
    "\n",
    "print(\"Tags: \", en_tblob.tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "DJeCWBioc6Wu",
    "outputId": "4d8f3d4c-2e15-4f15-f4c9-758a0c8cf7eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"USP classes are very boring\")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"As aulas da USP são muito chatas\"\n",
    "\n",
    "tblob = TextBlob(text)\n",
    "\n",
    "en_text = tblob.translate(to='en')\n",
    "\n",
    "en_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Z_pip7sRdLV0",
    "outputId": "e58a1206-ae67-48a8-b82f-2aa310a92f31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(classification='neg', p_pos=0.2782420508972421, p_neg=0.7217579491027579)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en = TextBlob(en_text.string, analyzer=NaiveBayesAnalyzer())\n",
    "\n",
    "en.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "i66U-_tP3Yv8",
    "outputId": "7d9f84f6-4d55-405d-8fdd-3551d098d808"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"As aulas da USP são muito chatas. Meu Deus!\")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo com uma forma de deixar todo o texto no mesmo indioma\n",
    "en_text = \"As aulas da USP são muito chatas. My god!\"\n",
    "\n",
    "#Exemplo 1\n",
    "tblob = TextBlob(en_text)\n",
    "pt_text = tblob.translate(from_lang='en', to='pt')\n",
    "\n",
    "pt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5hVs811vvx7d",
    "outputId": "49901b52-ddca-4a69-94bc-e2193f73d637"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As aulas da USP são muito chatas. Meu Deus!'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install translate\n",
    "from translate import Translator\n",
    "\n",
    "#Exemplo 2 usando outro pacote o \"translate\"\n",
    "en_text = \"As aulas da USP são muito chatas. My god!\"\n",
    "\n",
    "translator = Translator(to_lang=\"pt\")\n",
    "pt_text = translator.translate(en_text)\n",
    "\n",
    "pt_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tZFcDaAUp-f2"
   },
   "source": [
    "## SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ii4EiP-ciUGo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_sm==2.2.5\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
      "Requirement already satisfied: spacy>=2.2.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: thinc==7.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.1)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (46.4.0.post20200518)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.46.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.25.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.4.5.1)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\programdata\\anaconda3\\lib\\site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
      "Building wheels for collected packages: en-core-web-sm\n",
      "  Building wheel for en-core-web-sm (setup.py): started\n",
      "  Building wheel for en-core-web-sm (setup.py): finished with status 'done'\n",
      "  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.2.5-py3-none-any.whl size=12011743 sha256=fe20171926f7c961f395ef6ab71648fcc11f9f848e4ff03203fe0a792ac4b3fe\n",
      "  Stored in directory: C:\\Users\\BRJUVEN1\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-urbaknt8\\wheels\\51\\19\\da\\a3885266a3c241aff0ad2eb674ae058fd34a4870fef1c0a5a0\n",
      "Successfully built en-core-web-sm\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-2.2.5\n",
      "symbolic link created for C:\\ProgramData\\Anaconda3\\lib\\site-packages\\spacy\\data\\en <<===>> C:\\ProgramData\\Anaconda3\\lib\\site-packages\\en_core_web_sm\n",
      "[+] Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "[+] Linking successful\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\en_core_web_sm -->\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\spacy\\data\\en\n",
      "You can now load the model via spacy.load('en')\n",
      "Collecting pt_core_news_sm==2.2.5\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.2.5/pt_core_news_sm-2.2.5.tar.gz (21.2 MB)\n",
      "Requirement already satisfied: spacy>=2.2.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pt_core_news_sm==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: thinc==7.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.23.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.18.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (4.46.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (46.4.0.post20200518)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\programdata\\anaconda3\\lib\\site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.5.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2020.4.5.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.25.8)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.1.0)\n",
      "Building wheels for collected packages: pt-core-news-sm\n",
      "  Building wheel for pt-core-news-sm (setup.py): started\n",
      "  Building wheel for pt-core-news-sm (setup.py): finished with status 'done'\n",
      "  Created wheel for pt-core-news-sm: filename=pt_core_news_sm-2.2.5-py3-none-any.whl size=21186286 sha256=e9f9497967beae5621c5533c3d590fd969717bcc741caa96a1ab78eaf135b686\n",
      "  Stored in directory: C:\\Users\\BRJUVEN1\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-y36ni44o\\wheels\\c3\\f9\\0c\\5c014a36941a00f5df5fc0756cb961d7c457a978e697a6ce3b\n",
      "Successfully built pt-core-news-sm\n",
      "Installing collected packages: pt-core-news-sm\n",
      "Successfully installed pt-core-news-sm-2.2.5\n",
      "symbolic link created for C:\\ProgramData\\Anaconda3\\lib\\site-packages\\spacy\\data\\pt <<===>> C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pt_core_news_sm\n",
      "[+] Download and installation successful\n",
      "You can now load the model via spacy.load('pt_core_news_sm')\n",
      "[+] Linking successful\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pt_core_news_sm -->\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\spacy\\data\\pt\n",
      "You can now load the model via spacy.load('pt')\n"
     ]
    }
   ],
   "source": [
    "#!pip install spacy\n",
    "!python -m spacy download en\n",
    "!python -m spacy download pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ZERDUlN--4q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pt_core_news_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.2.5/pt_core_news_sm-2.2.5.tar.gz#egg=pt_core_news_sm==2.2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pt_core_news_sm==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.18.1)\n",
      "Requirement already satisfied: thinc==7.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (46.4.0.post20200518)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.23.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (4.46.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2020.4.5.1)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\programdata\\anaconda3\\lib\\site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.1.0)\n",
      "[+] Download and installation successful\n",
      "You can now load the model via spacy.load('pt_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "#!python -m spacy download en_core_web_lg\n",
    "!python -m spacy download pt_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wikgr3q7zs8W"
   },
   "source": [
    "Os modelos e linguagens que o SpaCy suporta: https://spacy.io/usage/models\n",
    "\n",
    "Detalhes do modelo em português: https://spacy.io/models/pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177
    },
    "colab_type": "code",
    "id": "bpF7RyFPa0Lj",
    "outputId": "5e99ed26-3f9a-4586-892d-fba94f4d16a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o\n",
      "l\n",
      "á\n",
      " \n",
      "t\n",
      "u\n",
      "r\n",
      "m\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "for x in \"olá turma\":\n",
    "  print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "cxv4W49BqDC_",
    "outputId": "c2643a5a-3e4d-455c-fd41-fcd95242c594"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.doc.Doc'>\n",
      "['Você', 'encontrou', 'o', 'livro', 'que', 'eu', 'te', 'falei', ',', 'Carla', '?']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('pt')\n",
    "\n",
    "doc = nlp(u'Você encontrou o livro que eu te falei, Carla?')\n",
    "\n",
    "print(type(doc))\n",
    "print([token.orth_ for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "zkxmhVTe16p4",
    "outputId": "57ea5150-3bd4-4ffe-bc09-e03f28ae3ce1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Você', 'encontrou', 'o', 'livro', 'que', 'eu', 'te', 'falei', ',', 'Carla', '?']\n"
     ]
    }
   ],
   "source": [
    "print([token.text for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "dvXJTq8ofR3m",
    "outputId": "339ea9c9-f94f-419e-afd3-dd7af45092f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc[0].orth_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "YXLpdMNH3XxY",
    "outputId": "ef6e92ff-2ded-478a-cb7f-5b41d08c3c4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V\n",
      "o\n",
      "c\n",
      "ê\n",
      " \n",
      "e\n",
      "n\n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "r\n",
      "o\n",
      "u\n",
      " \n",
      "o\n",
      " \n",
      "l\n",
      "i\n",
      "v\n",
      "r\n",
      "o\n",
      " \n",
      "q\n",
      "u\n",
      "e\n",
      " \n",
      "e\n",
      "u\n",
      " \n",
      "t\n",
      "e\n",
      " \n",
      "f\n",
      "a\n",
      "l\n",
      "e\n",
      "i\n",
      ",\n",
      " \n",
      "C\n",
      "a\n",
      "r\n",
      "l\n",
      "a\n",
      "?\n"
     ]
    }
   ],
   "source": [
    "#doc[1].orth_\n",
    "\n",
    "for i in doc[0:].orth_:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "kihe7mhKrZFQ",
    "outputId": "5d1346a8-6517-41d2-8e19-a440b1f82a8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Você', 'Você', 'PRON', 'nsubj', 'pronoun'),\n",
       " ('encontrou', 'encontrou', 'VERB', 'ROOT', 'verb'),\n",
       " ('o', 'o', 'DET', 'det', 'determiner'),\n",
       " ('livro', 'livro', 'NOUN', 'obj', 'noun'),\n",
       " ('que', 'que', 'PRON', 'obj', 'pronoun'),\n",
       " ('eu', 'eu', 'PRON', 'nsubj', 'pronoun'),\n",
       " ('te', 'te', 'VERB', 'obj', 'verb'),\n",
       " ('falei', 'falei', 'VERB', 'acl:relcl', 'verb'),\n",
       " (',', ',', 'PUNCT', 'punct', 'punctuation'),\n",
       " ('Carla', 'Carla', 'PROPN', 'conj', 'proper noun'),\n",
       " ('?', '?', 'PUNCT', 'punct', 'punctuation')]"
      ]
     },
     "execution_count": 248,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(token.text, token.orth_, token.pos_, token.dep_, spacy.explain(token.pos_)) for token in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p4IKxyc0ghgX"
   },
   "source": [
    "Uma lista completa de dependências sintáticas pode ser vista em: https://spacy.io/api/annotation#dependency-parsing \n",
    "\n",
    "Um bom material complementar para dependências sintáticas pode ser vista no [\"Stanford typed dependencies manual\"](https://nlp.stanford.edu/software/dependencies_manual.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "JGGhkVL5b_kb",
    "outputId": "b29510a7-f834-4a75-f34c-99d953fd42a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Você encontrou o livro que eu te falei, Carla?"
      ]
     },
     "execution_count": 249,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "lX_bRMWpKE3R",
    "outputId": "4715d82a-34cc-4898-ef8c-2f388b46da1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Você',\n",
       " 'encontrar',\n",
       " 'o',\n",
       " 'livrar',\n",
       " 'que',\n",
       " 'eu',\n",
       " 'te',\n",
       " 'falar',\n",
       " ',',\n",
       " 'Carla',\n",
       " '?']"
      ]
     },
     "execution_count": 250,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.lemma_ for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "yD_Mmy2YKE3U",
    "outputId": "bbdddf64-3a34-4a34-9edb-2e6aabdcbc51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['encontrar', ',', 'encontrar', ',', 'encontrar', ',', 'encontrar', ',', 'encontrar', ',', 'encontrar']\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'encontrardes, encontraram, encontrarão, encontrariam, encontrasse, encontraria')\n",
    "print([token.lemma_ for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AIbo-wEj5JUn"
   },
   "source": [
    "Reconhecimento de entidades nomeadas - NER: Named-Enntity Recognition.\n",
    "\n",
    "Utilizada para reconhecer pessoas, locais, empresas, datas, numerais e outros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "_NPR6lntKE3X",
    "outputId": "2e6d427d-7573-48d7-afc5-013812378875"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Pelé, Brasil, Academia Brasileira de Letras)\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Pelé um dos melhores escritores do Brasil, \\\n",
    "foi o primeiro presidente da Academia Brasileira de Letras')\n",
    "\n",
    "print(doc.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "F9APZK79KE3b",
    "outputId": "87a36046-8798-4083-c8b1-c769883723f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Pelé, 'PER', 'Named person or family.'),\n",
       " (Brasil, 'LOC', 'Non-GPE locations, mountain ranges, bodies of water'),\n",
       " (Academia Brasileira de Letras,\n",
       "  'ORG',\n",
       "  'Companies, agencies, institutions, etc.')]"
      ]
     },
     "execution_count": 253,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(entity, entity.label_, spacy.explain(entity.label_)) for entity in doc.ents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "colab_type": "code",
    "id": "qc0zcc6b_YZP",
    "outputId": "f530aec0-ac6d-4f8e-a463-ff5ff095453a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Pelé, 'PROPN'),\n",
       " (um, 'NUM'),\n",
       " (dos, 'ADP'),\n",
       " (melhores, 'ADJ'),\n",
       " (escritores, 'NOUN'),\n",
       " (do, 'ADP'),\n",
       " (Brasil, 'PROPN'),\n",
       " (,, 'PUNCT'),\n",
       " (foi, 'VERB'),\n",
       " (o, 'DET'),\n",
       " (primeiro, 'ADJ'),\n",
       " (presidente, 'NOUN'),\n",
       " (da, 'ADP'),\n",
       " (Academia, 'PROPN'),\n",
       " (Brasileira, 'PROPN'),\n",
       " (de, 'ADP'),\n",
       " (Letras, 'PROPN')]"
      ]
     },
     "execution_count": 254,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(entity, entity.pos_) for entity in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "Ru_7c5mpia4E",
    "outputId": "f05a3e6a-ee1e-43d4-8a0a-59e69b2893b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google | investirá | 6 | milhões | de | dólares | \n",
      "----\n",
      "Google - ORG - Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "doc8 = nlp(u'Google investirá 6 milhões de dólares')\n",
    "\n",
    "for token in doc8:\n",
    "    print(token.text, end =' | ')\n",
    "\n",
    "print('\\n----')\n",
    "\n",
    "for ent in doc8.ents:\n",
    "    print(ent.text + ' - ' + ent.label_ + ' - ' + str(spacy.explain(ent.label_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "RzVAI0Z6KE3g",
    "outputId": "5cf7c40c-c5c3-4ea7-d51b-d20e4066cd1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esta é a primeira sentença.\n",
      "Sr. esta é a segunda sentença.\n",
      "Esta é a terceira.\n",
      "Você já entendeu né?\n"
     ]
    }
   ],
   "source": [
    "doc4 = nlp(u'Esta é a primeira sentença. Sr. esta é a segunda sentença. Esta é a terceira. Você já entendeu né?')\n",
    "\n",
    "for sent in doc4.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "uv6ta7C_7D2J",
    "outputId": "ba909719-a379-4314-8aca-b81ec4508ef1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sr."
      ]
     },
     "execution_count": 257,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc4[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "5E6jPE6yh38K",
    "outputId": "a5887d88-9703-4de8-f17a-2dc84ae228c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sr.\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(doc4[6])\n",
    "print(doc4[6].is_sent_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "GPqiHvM7h8Np",
    "outputId": "1962ba7b-dce9-4606-8892-0c1ed531c058"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conselho', 'nem', 'tens', 'que', 'aos', 'final', 'meses', 'sua', 'tentar', 'devem', 'enquanto', 'quando', 'grandes', 'está', 'meus', 'vossos', 'cujo', 'nesse', 'esse', 'os', 'inicio', 'apenas', 'faz', 'lado', 'podem', 'fez', 'é', 'tuas', 'como', 'através', 'neste', 'bom', 'estivemos', 'ponto', 'corrente', 'assim', 'veja', 'oitava', 'dezoito', 'debaixo', 'fazia', 'aquele', 'mesmo', 'tiveste', 'qualquer', 'deverá', 'tipo', 'tarde', 'sim', 'todas', 'conhecido', 'quarta', 'faço', 'questão', 'contra', 'nada', 'minhas', 'vossa', 'aqueles', 'catorze', 'num', 'vos', 'vários', 'pois', 'estiveram', 'posso', 'com', 'foram', 'pouco', 'nossas', 'tenho', 'cedo', 'seu', 'forma', 'nove', 'eles', 'outras', 'longe', 'onde', 'zero', 'após', 'sabe', 'nunca', 'ali', 'por', 'mês', 'deste', 'tivestes', 'ou', 'vinda', 'vossas', 'vocês', 'foi', 'seis', 'cima', 'pouca', 'estive', 'oitavo', 'todo', 'ir', 'essa', 'quarto', 'do', 'desde', 'tentei', 'estes', 'vezes', 'esses', 'fazes', 'vós', 'segunda', 'cá', 'ainda', 'falta', 'muito', 'próxima', 'dezanove', 'eu', 'terceira', 'tão', 'és', 'sexto', 'lhe', 'na', 'outra', 'segundo', 'aqui', 'atrás', 'ser', 'grande', 'somente', 'era', 'embora', 'estar', 'próprio', 'parece', 'tu', 'bastante', 'ver', 'dar', 'posição', 'novo', 'cinco', 'minha', 'são', 'maiorias', 'fostes', 'cada', 'umas', 'logo', 'ela', 'vens', 'deve', 'ao', 'entre', 'partir', 'dá', 'seus', 'contudo', 'cuja', 'sobre', 'inclusive', 'de', 'pegar', 'isto', 'ambas', 'usar', 'oito', 'teu', 'conhecida', 'estou', 'primeira', 'último', 'tempo', 'quatro', 'grupo', 'terceiro', 'as', 'usa', 'quê', 'próximo', 'quanto', 'quer', 'também', 'nessa', 'irá', 'querem', 'da', 'à', 'ele', 'favor', 'adeus', 'somos', 'suas', 'meio', 'porquanto', 'fomos', 'ontem', 'apontar', 'mas', 'bem', 'coisa', 'aí', 'numa', 'fora', 'põe', 'nova', 'pelos', 'têm', 'foste', 'não', 'ligado', 'aquelas', 'só', 'doze', 'ambos', 'sistema', 'sem', 'fui', 'sexta', 'uns', 'tudo', 'momento', 'me', 'todos', 'vindo', 'no', 'um', 'nesta', 'portanto', 'algumas', 'lugar', 'antes', 'duas', 'apoia', 'temos', 'naquele', 'estão', 'parte', 'possível', 'aquilo', 'menor', 'fazem', 'uma', 'quieto', 'geral', 'fará', 'depois', 'você', 'números', 'porém', 'pelas', 'alguns', 'sob', 'sétima', 'puderam', 'caminho', 'sempre', 'agora', 'maior', 'quem', 'desse', 'máximo', 'vez', 'dezasseis', 'povo', 'possivelmente', 'daquele', 'treze', 'três', 'certamente', 'quero', 'lá', 'podia', 'em', 'algo', 'menos', 'quais', 'nosso', 'das', 'tem', 'talvez', 'daquela', 'sétimo', 'desta', 'perto', 'então', 'baixo', 'fim', 'onze', 'saber', 'vosso', 'número', 'dezassete', 'vêm', 'toda', 'estava', 'comprida', 'muitos', 'outros', 'iniciar', 'tanto', 'pelo', 'exemplo', 'sei', 'boa', 'vai', 'aquela', 'qual', 'nossa', 'nenhuma', 'teus', 'dizer', 'fazeis', 'mais', 'mal', 'diante', 'põem', 'tendes', 'dois', 'maioria', 'cento', 'comprido', 'demais', 'dão', 'área', 'certeza', 'porquê', 'mil', 'nós', 'valor', 'tanta', 'tiveram', 'dez', 'sou', 'vem', 'nossos', 'primeiro', 'tal', 'elas', 'para', 'apoio', 'esteve', 'des', 'quieta', 'estado', 'pôde', 'te', 'estás', 'este', 'já', 'quinta', 'ora', 'dentro', 'diz', 'ademais', 'nas', 'pode', 'tentaram', 'pela', 'poderá', 'estará', 'vão', 'esta', 'fazemos', 'local', 'às', 'tente', 'relação', 'estas', 'porque', 'nível', 'obrigado', 'disso', 'eventual', 'nuns', 'acerca', 'naquela', 'quinze', 'poder', 'fazer', 'isso', 'tua', 'custa', 'tivemos', 'ter', 'dizem', 'nos', 'estivestes', 'teve', 'for', 'tais', 'se', 'estiveste', 'quinto', 'meu', 'tive', 'novas', 'novos', 'sete', 'dessa', 'sois', 'obrigada', 'dos', 'além', 'direita', 'essas', 'breve', 'pontos', 'até', 'vinte', 'seria', 'vais'}\n"
     ]
    }
   ],
   "source": [
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "AWKYCRDojNR2",
    "outputId": "781fb044-be56-48d7-9a77-8a7e50f76946"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "413"
      ]
     },
     "execution_count": 260,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "u6UGby2DjU64",
    "outputId": "d9713a73-e1a4-44b9-ce44-a06f0017c9b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "XJtqP-KFjgem",
    "outputId": "bdab739f-b652-46d4-e4d4-e821a056773d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ligado',\n",
       " 'muitos',\n",
       " 'conselho',\n",
       " 'segunda',\n",
       " 'cá',\n",
       " 'outros',\n",
       " 'iniciar',\n",
       " 'tanto',\n",
       " 'ainda',\n",
       " 'vós']"
      ]
     },
     "execution_count": 276,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(list(set(nlp.Defaults.stop_words) - set(stopwords)))\n",
    "list(set(nlp.Defaults.stop_words) - set(stopwords))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "euRE5EWEi7aI"
   },
   "outputs": [],
   "source": [
    "doc = nlp(u'pegar')\n",
    "token = doc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IukkB7hUku9M"
   },
   "source": [
    "## Correspondência Baseada em Regras \n",
    "\n",
    "O spaCy oferece uma ferramenta de correspondência de regras chamada Matcher, que permite criar uma biblioteca de padrões de token e, em seguida, associar esses padrões a um objeto Doc para retornar uma lista de correspondências encontradas. Você pode combinar em qualquer parte do token, incluindo texto e anotações, e você pode adicionar vários padrões ao mesmo combinador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uutHbv8UkGaT"
   },
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "trlgtXz5lJ6J"
   },
   "source": [
    "Aqui matcher é um objeto que é emparelhado com o objeto Vocab atual. Podemos adicionar e remover matchers nomeados específicos para o matcher, conforme necessário."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZiJM5rJ1loqQ"
   },
   "source": [
    "Podemos encontrar o termo \"guarda-chuva\" como uma palavra ou duas, com ou sem um hífen. Nesta seção, vamos desenvolver um matcher que encontre todos os três:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iITO-2i-lBCH"
   },
   "outputs": [],
   "source": [
    "pattern1 = [{'LOWER': 'guardachuva'}]\n",
    "pattern2 = [{'LOWER': 'guarda'}, {'LOWER': 'chuva'}]\n",
    "pattern3 = [{'LOWER': 'guarda'}, {'IS_PUNCT': True}, {'LOWER': 'chuva'}]\n",
    "\n",
    "matcher.add('GuardaChuva', None, pattern1, pattern2, pattern3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "e5TSsvpsmDvV",
    "outputId": "4505494a-50b0-4eb7-ed0a-cb9b177c7a17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(9998440168381091967, 2, 3), (12789480426693079439, 4, 5), (9998440168381091967, 9, 10), (12789480426693079439, 12, 15), (9998440168381091967, 17, 18), (12789480426693079439, 19, 21)]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('Hoje eu esqueci meu guardachuva. \\\n",
    "Vou ter que comprar um novo guarda - chuva. \\\n",
    "Quanto custa um guarda chuva?')\n",
    "\n",
    "found_matches = matcher(doc)\n",
    "print(found_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "f3t8-Nw1fVFW",
    "outputId": "d066b5e2-1398-44a5-8940-599ff691d57f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "guarda chuva"
      ]
     },
     "execution_count": 280,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[4:5]\n",
    "doc[12:15]\n",
    "doc[19:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "TD4o3trJmflv",
    "outputId": "4cddb2e6-21f3-42bc-d8ee-6052ce1731d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9998440168381091967 Personalida 2 3 esqueci\n",
      "12789480426693079439 GuardaChuva 4 5 guardachuva\n",
      "9998440168381091967 Personalida 9 10 comprar\n",
      "12789480426693079439 GuardaChuva 12 15 guarda - chuva\n",
      "9998440168381091967 Personalida 17 18 custa\n",
      "12789480426693079439 GuardaChuva 19 21 guarda chuva\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in found_matches:\n",
    "    string_id = nlp.vocab.strings[match_id]\n",
    "    span = doc[start:end]\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ts7j9EGOhK-q"
   },
   "source": [
    "É possível usar opções de POS Tag e o Lema dos termos como no exemplo abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bT0aMgDWbpsT"
   },
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "pattern = [{'POS': 'VERB'}]\n",
    "\n",
    "matcher.add('Personalida', None, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "KRyd7YOgcbug",
    "outputId": "49984c0d-c8e1-4c0c-d072-ad265afbc7b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(9998440168381091967, 4, 5)]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('O presidente Barak Obama visitou o Brasil')\n",
    "\n",
    "found_matches = matcher(doc)\n",
    "print(found_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "TLD9iHbmmUN0",
    "outputId": "4327eeaf-b296-4266-c0a7-6bc87a6ebfa8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "visitou"
      ]
     },
     "execution_count": 289,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[4:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t2qY-3uTnFWA"
   },
   "source": [
    "Os seguintes quantificadores podem ser passados para a chave `'OP'`:\n",
    "\n",
    "<table><tr><th>OP</th><th>Descrição</th></tr>\n",
    "\n",
    "<tr ><td><span >\\!</span></td><td>Nega o padrão, exigindo que ele corresponda exatamente 0 vezes</td></tr>\n",
    "<tr ><td><span >?</span></td><td>Torna o padrão opcional, permitindo que ele corresponda 0 ou 1 vezes</td></tr>\n",
    "<tr ><td><span >\\+</span></td><td>Exige que o padrão corresponda a uma ou mais vezes</td></tr>\n",
    "<tr ><td><span >\\*</span></td><td>Permite que o padrão corresponda a zero ou mais vezes</td></tr>\n",
    "</table>\n",
    "\n",
    "**Outros atributos de token**\n",
    "\n",
    "<table><tr><th>Atributo</th><th>Descrição</th></tr>\n",
    "\n",
    "<tr ><td><span >`ORTH`</span></td><td>O texto exato do token</td></tr>\n",
    "<tr ><td><span >`LOWER`</span></td><td>O texto em caixa baixa</td></tr>\n",
    "<tr ><td><span >`LENGTH`</span></td><td>O tamanho do texto do token</td></tr>\n",
    "<tr ><td><span >`IS_ALPHA`, `IS_ASCII`, `IS_DIGIT`</span></td><td>O texto do token consiste de alfanuméricos, ASCII, digitos</td></tr>\n",
    "<tr ><td><span >`IS_LOWER`, `IS_UPPER`, `IS_TITLE`</span></td><td>O texto do toen esta em  lowercase, uppercase, titlecase</td></tr>\n",
    "<tr ><td><span >`IS_PUNCT`, `IS_SPACE`, `IS_STOP`</span></td><td>Token é puntuação, espaço, stop-word</td></tr>\n",
    "<tr ><td><span >`LIKE_NUM`, `LIKE_URL`, `LIKE_EMAIL`</span></td><td>Texto do token se parece um numero, URL, email</td></tr>\n",
    "<tr ><td><span >`POS`, `TAG`, `DEP`, `LEMMA`, `SHAPE`</span></td><td>O token em sua representação de POS Tag, dependência, </td></tr>\n",
    "<tr ><td><span >`ENT_TYPE`</span></td><td>O tipo de entidade do token</td></tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "\n",
    "Para saber mais sobre esta função da lib SpaCy: \n",
    "\n",
    "https://spacy.io/api/matcher\n",
    "\n",
    "https://spacy.io/usage/rule-based-matching\n",
    "\n",
    "https://spacy.io/usage/linguistic-features#section-rule-based-matching"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Aula 4 IA PLN - Demo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
