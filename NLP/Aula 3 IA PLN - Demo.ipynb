{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JdelQOET5rDj"
   },
   "source": [
    "#**Processamento de Linguagem Natural**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K0wg8wf1GSeD"
   },
   "source": [
    "## Stemmer (Stemização)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yfwMue5RGR8B"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "exemplos = [\"connection\",\"connections\",\"connective\",\"connecting\",\"connected\"]\n",
    "print(exemplos)\n",
    "\n",
    "for word in exemplos:\n",
    "  print(ps.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YiXeQyMcAx4Y"
   },
   "outputs": [],
   "source": [
    "# Outro exemplo\n",
    "ps = PorterStemmer()\n",
    "exemplos = [\"go\",\"going\",\"goes\",\"gone\",\"went\"]\n",
    "print(exemplos)\n",
    "\n",
    "for word in exemplos:\n",
    "  print(ps.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aIvuXLMeqUd9"
   },
   "outputs": [],
   "source": [
    "# Stemização\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.rslp import RSLPStemmer\n",
    "import nltk \n",
    "nltk.download('rslp')\n",
    "\n",
    "doc = [\"pedra\",\"pedreira\"]\n",
    "print(doc)\n",
    "\n",
    "ps = PorterStemmer()\n",
    "rslp = RSLPStemmer()\n",
    "\n",
    "for word in doc:\n",
    "    print(ps.stem(word), ' - ', rslp.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bVDjrt-eT4MV"
   },
   "source": [
    "## Aplicar Stemmer em uma frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nGuydG4xrJFd"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'text': [\n",
    "      'Sobre MBA? Eu gostei muito do MBA da FIAP',\n",
    "      'O MBA da FIAP pode melhorar, não gostei muito'\n",
    "    ],\n",
    "    'class': [\n",
    "        'positivo',\n",
    "        'negativo'\n",
    "    ]})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S6_SwqMGibny"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "df['tokens'] = df.text.apply(word_tokenize)\n",
    "df['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HBJ-oLU9T3jT"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.rslp import RSLPStemmer\n",
    "import nltk\n",
    "nltk.download('rslp')\n",
    "\n",
    "tokens = df.tokens[0]\n",
    "tokens = tokens + df.tokens[1]\n",
    "\n",
    "ps = PorterStemmer()\n",
    "rslp = RSLPStemmer()\n",
    "\n",
    "for tok in tokens:\n",
    "  print('Original: %s \\t\\t  PorterStemmer: %s \\t\\t RSLPStemmer: %s' % (tok, ps.stem(tok), rslp.stem(tok)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "37nqnDh-qVnA"
   },
   "outputs": [],
   "source": [
    "# O Porter foi criado para o inglês e o RSLP para o português"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9QGwgdjvSW7L"
   },
   "source": [
    "NLTK = Natural Language Tool Kit\n",
    "\n",
    "RSLP = Removedor de Sulfixos da Língua Portuguesa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zhTMo3h0oFA7"
   },
   "source": [
    "## Quantos unigramas existem após aplicar Stemmer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YlUI2NgDhufq"
   },
   "outputs": [],
   "source": [
    "','.join(['Anderson', 'Dourado'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k_3LR9sO0hRm"
   },
   "outputs": [],
   "source": [
    "from nltk.stem.rslp import RSLPStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "rslp = RSLPStemmer()\n",
    "\n",
    "def stem_pandas(line):\n",
    "  return ' '.join([rslp.stem(token) for token in line])\n",
    "\n",
    "df['stemmer'] = df.tokens.apply(stem_pandas)\n",
    "\n",
    "df.stemmer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NFiA2cAORmpc"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "#vect = CountVectorizer(ngram_range=(1,1), stop_words=stopwords)\n",
    "vect = CountVectorizer(ngram_range=(1,1))\n",
    "vect.fit(df.stemmer)\n",
    "\n",
    "text_vect = vect.transform(df.stemmer)\n",
    "\n",
    "print('UNIGRAMAS sem STOPWORDS', text_vect.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ofA1n_IMkb_t"
   },
   "source": [
    "Unigramas sem aplicar o steamm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QAfnfeu8kbSI"
   },
   "outputs": [],
   "source": [
    "#stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "#vect = CountVectorizer(ngram_range=(1,1), stop_words=stopwords)\n",
    "vect = CountVectorizer(ngram_range=(1,1))\n",
    "vect.fit(df.text)\n",
    "\n",
    "text_vect = vect.transform(df.text)\n",
    "\n",
    "print('UNIGRAMAS sem STOPWORDS', text_vect.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wCHgWx60kbPq"
   },
   "outputs": [],
   "source": [
    "# Não diferença pois o texto não tem muitas variações de palavras que possam ser reduzidas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kr8ZxTp-pVPC"
   },
   "source": [
    "Outra função de stematização do NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ngaGMoCjpL4Q"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "print(\" \".join(SnowballStemmer.languages)) # See which languages are supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v1inKMGdpLu4"
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"portuguese\") # Escolha a linguagem\n",
    "\n",
    "palavras = ['pedra','pedreira','criar']\n",
    "\n",
    "for p in palavras:\n",
    "  print(stemmer.stem(p)) # Stem a palavra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cDR2TTl-EnXs"
   },
   "source": [
    "## Lemmatizer (Lematização)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cBLzygcrElkJ"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "exemplos = [\"connection\",\"connections\",\"connective\",\"connecting\",\"connected\"]\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "for word in exemplos:\n",
    "    print(wnl.lemmatize(word,\"v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2wTZpIniE39a"
   },
   "outputs": [],
   "source": [
    "exemplos = [\"go\",\"going\",\"goes\",\"gone\",\"went\"]\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "for word in exemplos:\n",
    "  print(wnl.lemmatize(word,\"v\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ndw8rAQbofuL"
   },
   "source": [
    "Vamos ver lematização em palavras do português mais para frente, pois o NLTK não possui lematização em português.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IqCkOL0C5-FC"
   },
   "source": [
    "## Contagem de Termos - UNIGRAMA\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d4CKjpwJ2DD2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'text': [\n",
    "      'Sobre MBA ? Eu gostei muito do MBA da FIAP',\n",
    "      'O MBA da FIAP pode melhorar, não gostei muito'\n",
    "    ],\n",
    "    'class': [\n",
    "        'positivo',\n",
    "        'negativo'\n",
    "    ]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G6kSv69h2jKs"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer(ngram_range=(1,1))\n",
    "#vect = CountVectorizer(ngram_range=(2,2))\n",
    "vect.fit(df.text)\n",
    "count_vect = vect.transform(df.text)\n",
    "\n",
    "print(pd.DataFrame(count_vect.A, columns=vect.get_feature_names()).T.to_string())\n",
    "#print(pd.DataFrame(count_vect.A, columns=vect.get_feature_names()).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TUTv5MDZE0jr"
   },
   "source": [
    "## TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LHgB0DuUCn65"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# ao usar o TfidfVectorizer() o default ngram_range=unigrama, use_idf=True, norm='l2', lowercase=True, max_df e min_df=1, smooth_idf=True, sublinear_tf=False\n",
    "vect = TfidfVectorizer(ngram_range=(1,1), use_idf=False, norm='l1')\n",
    "vect.fit(df.text)\n",
    "tf_vect = vect.transform(df.text)\n",
    "\n",
    "print(pd.DataFrame(tf_vect.A, columns=vect.get_feature_names()).T.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qCpY8Zww3o47"
   },
   "outputs": [],
   "source": [
    "#vect.get_stop_words()\n",
    "#vect.get_params(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dxG2g5mInypI"
   },
   "source": [
    "## TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XcJsUXuHFTnM"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# ao usar o TfidfVectorizer() o default ngram_range=unigrama, use_idf=True, norm='l2', lowercase=True, max_df e min_df=1, smooth_idf=True, sublinear_tf=False\n",
    "vect = TfidfVectorizer() \n",
    "vect.fit(df.text)\n",
    "tfidf_vect = vect.transform(df.text)\n",
    "\n",
    "print(pd.DataFrame(tfidf_vect.A, columns=vect.get_feature_names()).T.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zb4iAoq2ZoqW"
   },
   "source": [
    "Existe uma diferenca no cálculo original do TF-IDF apresentados pelos livros em relação ao padrão urilizado pelo Scikit Learn. A ideia dessa diferença é evitar divisões por zero.\n",
    "\n",
    "Formúla original:\n",
    "\n",
    "    TF-IDFw1 = TFw1 * IDFw1\n",
    "    IDFw1 = loge(D/Dw1)\n",
    "    D = total de documentos | Dw1 = Quantidade de documentos em que o termo aparece\n",
    "\n",
    "----\n",
    "Formúla do sklearn:\n",
    "Muda o cálculo do IDFw1\n",
    "\n",
    "    IDFw! = loge(1+D/1+Dw1)+1\n",
    "\n",
    "Com o paâmetro smooth_idf=False\n",
    "\n",
    "    IDFw! = loge(D/Dw1)+1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OYvr0cay4JbU"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# ao usar o TfidfVectorizer() o default ngram_range=unigrama, use_idf=True, norm='l2', lowercase=True, max_df e min_df=1, smooth_idf=True, sublinear_tf=False\n",
    "vect = TfidfVectorizer(smooth_idf=False)\n",
    "#vect = TfidfVectorizer(smooth_idf=False, max_df=1, min_df=1)\n",
    "vect.fit(df.text)\n",
    "tfidf_vect = vect.transform(df.text)\n",
    "\n",
    "print(pd.DataFrame(tfidf_vect.A, columns=vect.get_feature_names()).T.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HEps9zD-u4v_"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "tfidf_vect.data\n",
    "tfidf_vect.A\n",
    "vect.get_feature_names()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i0WHVK8HYG5r"
   },
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer\n",
    "\n",
    "\n",
    "https://scikit-learn.org/stable/modules/feature_extraction.html\n",
    "\n",
    "O cáculo do TF-IDF das classes TfidfTransformer e TfidfVectorizer do scikit-learn diferem ligeiramente da notação padrão de livros didáticos que define o IDF.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "owZf_DaUomwT"
   },
   "source": [
    "## Modelo com n-grama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pbiAa2z89dy3"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M4lp9qev2BwO"
   },
   "outputs": [],
   "source": [
    "df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A3p0_VlNmzAY"
   },
   "outputs": [],
   "source": [
    "# treinando um modelo de árevore de decisão\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(tfidf_vect, df['class'])\n",
    "\n",
    "print('D Tree: ', tree.score(tfidf_vect, df['class'])) # retorna a acurracy - precisão do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MD07UNay3hA5"
   },
   "outputs": [],
   "source": [
    "tree.score(tfidf_vect, df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OuGLwdhUpuIZ"
   },
   "outputs": [],
   "source": [
    "vetor = vect.transform(['a vovo juju adora abacate'])\n",
    "\n",
    "print('D Tree: ', tree.predict(vetor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R2-ZCeUkYiJ1"
   },
   "source": [
    "Salvando o modelo treinado e o vetor de tranformação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2R6-1s4wqEiq"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(tree, open('minhaarvore.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_DE_UGqF1tI8"
   },
   "outputs": [],
   "source": [
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4CsH-JyC3rGI"
   },
   "outputs": [],
   "source": [
    "blaaaaa = pickle.load(open('minhaarvore.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DLsZNb1R4EIk"
   },
   "outputs": [],
   "source": [
    "print('D Tree: ', blaaaaa.predict(texto)) # texto = vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_vdnmYmE4PYL"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)\n",
    "\n",
    "# mostrar a estrutura de pastas do google drive montado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hKUrqfZ_ABaC"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(tree, open('/content/gdrive/My Drive/FIAP/NLP/minhaarvore.pkl', 'wb'))\n",
    "\n",
    "pickle.dump(vect, open('/content/gdrive/My Drive/FIAP/NLP/vetorizador.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Aula 3 IA PLN - Demo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
