{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"right\">Peter Norvig, Nov. 2017</div>\n",
    "\n",
    "# Bad Grade, Good Experience\n",
    "\n",
    "Recently I was asked a question I hadn't thought about in decades: \n",
    "\n",
    "> *As a student, did you ever get a bad grade on a programming assignment?* \n",
    "\n",
    "I've forgotten most of my assignments, but there is one I do remember. It was something like this:\n",
    "\n",
    "# The Concordance Assignment\n",
    "\n",
    "> *Using the [`Snobol`](http://www.snobol4.org/) language, read lines of text from the standard input and print a *concordance*, which is an alphabetized list of words in the text, with the line number(s) where each word appears. Words with different capitalization (like \"A\" and \"a\") should be merged into one entry.*\n",
    "\n",
    "After studying Snobol a bit, I realized that the expected solution was along these lines:\n",
    "\n",
    "1. Create an empty hash table whose keys will be words and values will be lists of line numbers.\n",
    "2. Read the lines of text (tracking the line numbers), split them into words, and build up the list of line numbers for each word.\n",
    "3. Convert the hash table into a two-dimensional array where each row has the two columns `[word, line_numbers]`.\n",
    "4. Write a function to sort the array alphabetically (`sort` is not built-in to Snobol).\n",
    "5. Write a function to print the array.\n",
    "\n",
    "That would be around 40 to 60 lines of code; an easy task. But I noticed three interesting things about Snobol:\n",
    "\n",
    "*   '`$`' is an *indirection* operator, so if the variable `'word'` has the value `\"A\"`, then `'$word = x'` is the same as `'A = x'`.\n",
    "*   Uninitialized variables are treated as the empty string, so `'A = A + \"text\"'` works even if  we haven't seen `'A'` before.\n",
    "*   When the program ends, the Snobol interpreter \n",
    "prints out each variable (in sorted order), with its value, as a debugging aid.\n",
    "\n",
    "That means I could use `$` to do away with the hash table and array data structures, eliminating steps 1, 3, 4, and 5, and just do step 2! \n",
    "\n",
    "# The Concordance Solution\n",
    "\n",
    "I ended up with a program similar to the following (translated from Snobol to Python, but with `'$word'` indirection):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "program = \"\"\"\n",
    "for i, line in enumerate(input):\n",
    "    for word in re.findall(\"[A-Z]+\", line.upper()):\n",
    "        $word = $word + i + \", \"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's just 3 lines, not 40 to 60! \n",
    "\n",
    "To test the program, I'll write a mock Snobol/Python interpreter, which at heart is just a call to the Python interpreter, `exec(program)`, except that it handles the three things I mentioned about the Snobol interpreter, plus one more:\n",
    "\n",
    "1. `$word` gets translated as `_globals[word]`.\n",
    "2. The interpreter calls `exec(program, _globals)`, where `_globals` is a `defaultdict` that makes variables default to the empty string.\n",
    "3. After the `exec` completes, the user-defined variables (but not the built-in ones) are printed.\n",
    "4. Concatenating a string with an integer coerces the `int` to `str` automatically. I'll handle that with a `Str` class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "def snobol(program, data=''):\n",
    "    \"\"\"A Python interpreter with four Snobol-ish features:\n",
    "    1. $word indirection; 2. variables default to empty string; \n",
    "    3. post-mortem dump;  4. automatic coercing to string\"\"\"\n",
    "    program = re.sub(r'\\$(\\w+)', r'_globals[\\1]', program) # 1. \n",
    "    _globals = defaultdict(Str, vars(__builtins__))        # 4., 2.\n",
    "    _globals.update(re=re, input=data.splitlines(), _globals=_globals)\n",
    "    builtins = set(_globals) | {'__builtins__'}\n",
    "    try:\n",
    "        exec(program, _globals)\n",
    "    finally:\n",
    "        print('-' * 79)                                    # 3.     \n",
    "        for name in sorted(_globals):\n",
    "            if name not in builtins:\n",
    "                print('{:10} = {}'.format(name, _globals[name]))\n",
    "                \n",
    "class Str(str):\n",
    "    \"String class with automatic coercion for +\"\n",
    "    def __add__(self, other):  return Str(str(self) + str(other))\n",
    "    def __radd__(self, other): return Str(str(other) + str(self))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the program on some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"\"\"\n",
    "There she was just a-walkin' down the street, \n",
    "Singin' \"Do wah diddy diddy dum diddy do\"\n",
    "Snappin' her fingers and shufflin' her feet, \n",
    "Singin' \"Do wah diddy diddy dum diddy do\"\n",
    "She looked good (looked good), \n",
    "She looked fine (looked fine)\n",
    "She looked good, she looked fine \n",
    "And I nearly lost my mind\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "A          = 1, \n",
      "AND        = 3, 8, \n",
      "DIDDY      = 2, 2, 2, 4, 4, 4, \n",
      "DO         = 2, 2, 4, 4, \n",
      "DOWN       = 1, \n",
      "DUM        = 2, 4, \n",
      "FEET       = 3, \n",
      "FINE       = 6, 6, 7, \n",
      "FINGERS    = 3, \n",
      "GOOD       = 5, 5, 7, \n",
      "HER        = 3, 3, \n",
      "I          = 8, \n",
      "JUST       = 1, \n",
      "LOOKED     = 5, 5, 6, 6, 7, 7, \n",
      "LOST       = 8, \n",
      "MIND       = 8, \n",
      "MY         = 8, \n",
      "NEARLY     = 8, \n",
      "SHE        = 1, 5, 6, 7, 7, \n",
      "SHUFFLIN   = 3, \n",
      "SINGIN     = 2, 4, \n",
      "SNAPPIN    = 3, \n",
      "STREET     = 1, \n",
      "THE        = 1, \n",
      "THERE      = 1, \n",
      "WAH        = 2, 4, \n",
      "WALKIN     = 1, \n",
      "WAS        = 1, \n",
      "i          = 8\n",
      "line       = And I nearly lost my mind\n",
      "word       = MIND\n"
     ]
    }
   ],
   "source": [
    "snobol(program, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Oops!** The post-mortem printout includes the variables `i`, `line`, and `word`. Reluctantly, I'll increase the program's line count by 33%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "A          = 1, \n",
      "AND        = 3, 8, \n",
      "DIDDY      = 2, 2, 2, 4, 4, 4, \n",
      "DO         = 2, 2, 4, 4, \n",
      "DOWN       = 1, \n",
      "DUM        = 2, 4, \n",
      "FEET       = 3, \n",
      "FINE       = 6, 6, 7, \n",
      "FINGERS    = 3, \n",
      "GOOD       = 5, 5, 7, \n",
      "HER        = 3, 3, \n",
      "I          = 8, \n",
      "JUST       = 1, \n",
      "LOOKED     = 5, 5, 6, 6, 7, 7, \n",
      "LOST       = 8, \n",
      "MIND       = 8, \n",
      "MY         = 8, \n",
      "NEARLY     = 8, \n",
      "SHE        = 1, 5, 6, 7, 7, \n",
      "SHUFFLIN   = 3, \n",
      "SINGIN     = 2, 4, \n",
      "SNAPPIN    = 3, \n",
      "STREET     = 1, \n",
      "THE        = 1, \n",
      "THERE      = 1, \n",
      "WAH        = 2, 4, \n",
      "WALKIN     = 1, \n",
      "WAS        = 1, \n"
     ]
    }
   ],
   "source": [
    "program = \"\"\"\n",
    "for i, line in enumerate(input):\n",
    "    for word in re.findall(\"[A-Z]+\", line.upper()):\n",
    "        $word = $word + i + \", \"\n",
    "del i, line, word\n",
    "\"\"\"\n",
    "\n",
    "snobol(program, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looks good to me! \n",
    "\n",
    "But sadly, the grader for the course did not agree, complaining that my program was not extensible: what if I wanted to cover two or more files in one run? What if I wanted the output to have a slightly different format? I argued that [YAGNI](https://en.wikipedia.org/wiki/You_aren%27t_gonna_need_it), and if the requirements\n",
    "changed, *then* I would write the necessary 40 or 60 lines, but there's no sense doing that until then. The grader was not impressed with my arguments and I got  points taken off. \n",
    "\n",
    "Still, I was happy with my program. I felt like the\n",
    "purpose of the assignment was to get familiar with a new programming language with some different  idioms/paradigms. By using the indirection operator I learned more about \"thinking different\" than if I had written the expected program.\n",
    "\n",
    "# TFW you flunk AI\n",
    "\n",
    "Here's another example that I had completely forgotten about until 2016, when I was cleaning out a filing cabinet and came across my old college transcript. It turns out that *I flunked an AI course!* (Or at least, didn't complete it.) This course was offered by Prof. Richard Millward in the Cognitive Science program.  I certainly remember a lot of influential material from this class: we read David Marr, we read Winston's just-published *Psychology of Computer Vision*, we read a chapter from Duda and Hart which was then only a few years old. The things I learned in that course have stuck with me for decades, but one thing that didn't stick is that, according to my transcript, I never completed the course! I'm not sure what happened. I did an independent study with Ulf Grenander that semester; my best guess\n",
    "is that when I started doing the independent study that would have put me over some limit, and so I had to drop the AI course.  \n",
    "\n",
    "So in both the concordance program and the Cognitive Science AI class, I had a great experience and I learned a lot, even if it wasn't well-reflected in official credit. The moral is: look for the good experiences, and don't worry about the official credit.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
